{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef37655",
   "metadata": {},
   "source": [
    "# Machine Learning analysis of data about Competency Assessment of Students from HE Biotech Academic Programs\n",
    "\n",
    "**Index**\n",
    ">\n",
    "> 1. [Data loading and preparation for Machine Learning for Stratified 10-fold Cross-Validation.](#1-data-loading-and-preparation-for-machine-learning-for-stratified-10-fold-cross-validation)\n",
    ">\n",
    "> 2. [Random Forest definition, training, and validation.](#2-random-forest-definition-training-and-validation)\n",
    ">\n",
    "> 3. [Deep Learning neural network for one-class classification with Pytorch, definition, training, and validation.](#3-deep-learning-neural-network-for-one-class-classification-with-pytorch-definition-training-and-validation)\n",
    ">\n",
    "> 4. [Statistical tests for comparing RandomForest and Deep Leaning model across all folds](#4-statistical-tests-for-comparing-randomforest-and-deep-leaning-model-across-all-folds)\n",
    ">\n",
    "> 5. [Interpretability of the RandomForest using SHAP values](#5-interpretability-of-the-randomforest-using-shap-values)\n",
    ">\n",
    "> 6. [PCA and FAMD analysis](#6-factor-analysis-of-mixed-data)\n",
    "\n",
    "**Dataset Bio_students_v5.6.csv is the result of the data preparation process with the notebook** __Tec21_biotecnology_competencies.ipynb__ **using the dataset in:** https://doi.org/10.57687/FK2/R9LOXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, RocCurveDisplay\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, \\\n",
    "    precision_score, recall_score, f1_score, classification_report, precision_score, \\\n",
    "    precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12382a45",
   "metadata": {},
   "source": [
    "## 1. Data loading and preparation for Machine Learning for Stratified 10-fold Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe and showing some information\n",
    "bio_df = pd.read_csv('../sourcecode/EICData/Bio_students_v5.6.csv')\n",
    "bio_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# Remove \"ID\" column\n",
    "bio_df.drop('ID', axis=1, inplace=True) \n",
    "bio_df['last_col'] = bio_df['Assigned']\n",
    "bio_df.drop(columns=['Assigned', 'isRegular'], inplace=True)\n",
    "bio_df.rename(columns={'last_col':'Assigned'}, inplace=True)\n",
    "# There were an empty string category of the variable Modality\n",
    "bio_df['Modality'] = bio_df['Modality'].replace(r'^\\s*$', 'Unknown', regex=True)\n",
    "# Remove records with any NaN \n",
    "bio_df.dropna(inplace=True)\n",
    "bio_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding also boolean variables include=['object']\n",
    "columnas_categorical = bio_df.select_dtypes(exclude=['int64', 'float64']).columns.tolist() \n",
    "# Excluding also boolean variables\n",
    "columnas_numerical = bio_df.select_dtypes(include=['int64', 'float64']).columns.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13665022",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "# Remove class var if it is in the categorical list\n",
    "if 'Assigned' in (columnas_categorical):\n",
    "    columnas_categorical.remove('Assigned')\n",
    "# Remove class var if it is in the numeric list\n",
    "if 'Assigned' in (columnas_numerical):\n",
    "    columnas_numerical.remove('Assigned')\n",
    "\n",
    "# Encoding categorical columns\n",
    "df_clean_shuffled = bio_df.sample(frac=1)\n",
    "y = df_clean_shuffled['Assigned'].astype('int')\n",
    "\n",
    "# Encode full dataset first\n",
    "# We have avoid dropping the first category, because RandomForest is better if having all categories explicitly\n",
    "full_preprocessor = ColumnTransformer([\n",
    "    ('num', MinMaxScaler(), columnas_numerical),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', #drop='None', \n",
    "                          sparse_output=False), \n",
    "            columnas_categorical)\n",
    "])\n",
    "X_encoded = full_preprocessor.fit_transform(df_clean_shuffled)\n",
    "\n",
    "# Ensure no value is greater than 1.0\n",
    "X_encoded = np.clip(X_encoded, 0, 1)\n",
    "\n",
    "# Get feature names after encodings\n",
    "encoded_features = []\n",
    "for col in full_preprocessor.transformers_:\n",
    "    if col[0] == 'num':\n",
    "        encoded_features.extend(col[2])  # numeric columns\n",
    "    elif col[0] == 'cat':\n",
    "        # Get one-hot encoded names\n",
    "        encoder = col[1]\n",
    "        # Comment if not using drop='First'\n",
    "        encoded_features.extend([f\"{col[2][i]}_{cat}\" \n",
    "                               for i in range(len(col[2])) \n",
    "                               for cat in encoder.categories_[i]])\n",
    "        # Uncomment if using drop='First'\n",
    "        # categories = encoder.categories_\n",
    "        # for i, feature in enumerate(col[2]):\n",
    "        #     # Skip the first category if drop='first'\n",
    "        #     for cat in categories[i][1:]:\n",
    "        #         encoded_features.append(f\"{feature}_{cat}\")\n",
    "\n",
    "# Convert back to DataFrame with proper column names\n",
    "X_encoded = pd.DataFrame(X_encoded, columns=encoded_features)\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_splitter(X_encoded, y, n_splits=10):\n",
    "    #  Modficar para realizar entrenamiento del modelo con los datos de X_data\n",
    "    Train = X_encoded    \n",
    "    labels = y\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cross_val_data = skf.split(Train, labels)\n",
    "    return cross_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b52f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same cross-validation splits and codified data for both algorithms\n",
    "cross_val_idxs = cross_val_splitter(X_encoded, y, n_splits = 10)\n",
    "\n",
    "# Create a list to store each fold's data\n",
    "cross_val_folds = []\n",
    "\n",
    "# Loop through each fold and store the indices in a dictionary\n",
    "for fold, (train, test) in enumerate(cross_val_idxs):\n",
    "    fold_data = {\n",
    "        'fold': fold,\n",
    "        'train': list(train.astype('int')),\n",
    "        'test': list(test.astype('int'))\n",
    "    }\n",
    "    cross_val_folds.append(fold_data)\n",
    "\n",
    "# for fold in cross_val_folds:\n",
    "#     print(f'Train: {cross_val_folds[0]['train']}')\n",
    "#     print(f'Test {cross_val_folds[0]['test']}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0583",
   "metadata": {},
   "source": [
    "## 2. Random Forest definition, training, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b45b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Setup\n",
    "\n",
    "rf_biotech = RandomForestClassifier(\n",
    "    n_estimators=100,  # Default number of trees\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # It balance the weight for each class accoridng to the imbalance ratio\n",
    "    verbose=False,\n",
    "    n_jobs=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb83a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_cross_val_RandomForest(cross_val_idxs, X_encoded, y, rf_biotech):\n",
    "    print('Stratified 10-Fold Cross-Validation with RandomForest')\n",
    "\n",
    "    os.makedirs(\"fold_plots\", exist_ok=True)\n",
    "    tprs, aucs = [], []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    metrics = {\n",
    "        'Iteration': [],\n",
    "        'AUC': [],\n",
    "        'Precision_Class0': [],\n",
    "        'Precision_Class1': [],\n",
    "        'Recall_Class0': [],\n",
    "        'Recall_Class1': [],\n",
    "        'F1_Class0': [],\n",
    "        'F1_Class1': [],\n",
    "        'ConfusionMatrix': []\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fig, ax = plt.subplots()\n",
    "    # Use manually stratified folds to explore the entire dataset\n",
    "    # fold_size = int(len(X_encoded.index)/n_splits)\n",
    "    # for index in range(n_splits):\n",
    "    for fold in cross_val_idxs:\n",
    "        # Split the data\n",
    "        index = fold['fold']\n",
    "        train_idx = fold['train']\n",
    "        test_idx = fold['test']\n",
    "        print(f'\\nFold {index}, Train size {len(train_idx)}, Test size {len(test_idx)}')\n",
    "        X_train_fold, X_val_fold = X_encoded.iloc[train_idx], X_encoded.iloc[test_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx].values, y.iloc[test_idx].values\n",
    "        # X_train, X_test = X_encoded.iloc[train_idx], X_encoded.iloc[test_idx]\n",
    "        # y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        rf_biotech.fit(X_train_fold, y_train_fold) # This statement retrains the model from scratch\n",
    "        # model_loaded.fit(X_train, y_train) # I am affraid this statement is using the model pretrained with train data\n",
    "        # Calcular la Curva AUC\n",
    "        plot = RocCurveDisplay.from_estimator(\n",
    "            rf_biotech, X_val_fold, y_val_fold,\n",
    "            # name=\"Fold {}\".format(index),\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # Then, update the label with formatted AUC\n",
    "        plot.line_.set_label(\"Fold {} (AUC = {:.4f})\".format(index, plot.roc_auc))\n",
    "\n",
    "        # Interpolate TPR for averaging\n",
    "        interp_tpr = np.interp(mean_fpr, plot.fpr, plot.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(plot.roc_auc)\n",
    "\n",
    "        # Predecir los datos de entrenamiento\n",
    "        y_pred = rf_biotech.predict(X_val_fold)\n",
    "\n",
    "        # Guardar métricas en un diccionario\n",
    "        metrics['Iteration'].append(index + 1)\n",
    "        metrics['AUC'].append(plot.roc_auc)\n",
    "        metrics['ConfusionMatrix'].append(confusion_matrix(y_val_fold, y_pred))\n",
    "        for cls in [0, 1]:\n",
    "            metrics[f'Precision_Class{cls}'].append(precision_score(y_val_fold, y_pred, pos_label=cls, zero_division=0))\n",
    "            metrics[f'Recall_Class{cls}'].append(recall_score(y_val_fold, y_pred, pos_label=cls, zero_division=0))\n",
    "            metrics[f'F1_Class{cls}'].append(f1_score(y_val_fold, y_pred, pos_label=cls, zero_division=0))\n",
    "    \n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        title=\"ROC Curves Across Folds\",\n",
    "    )\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"fold_plots/roc_cv_randomForest_kfold.pdf\")\n",
    "\n",
    "    # Convert to DataFrame to save it and analyze it\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv('fold_plots/RandomForest_Metric_Summary.csv', index=False)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics_summary = train_validate_cross_val_RandomForest(cross_val_folds, X_encoded, y, rf_biotech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068794b",
   "metadata": {},
   "source": [
    "## 3. Deep Learning neural network for one-class classification with Pytorch, definition, training, and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneClassNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(OneClassNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        # x = self.sigmoid(self.fc6(x)) \n",
    "        x = self.fc6(x) \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86810f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train, validate, and test the model\n",
    "def train_validate_test_model(cross_val_idxs, X_encoded, y, batch_size=batch_size, epochs=10, learning_rate=0.001, patience=10):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")       \n",
    "        \n",
    "    # Lists to store results\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    fold_auc_scores = []\n",
    "    fold_metrics = []\n",
    "    max_loss = float('inf')  # Initialize to a large value\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for index in cross_val_idxs:\n",
    "        fold = index['fold']\n",
    "        # Original indices from cross-validation\n",
    "        train_idx = index['train']\n",
    "        test_idx = index['test']\n",
    "\n",
    "        # Identify negative and positive samples in training set\n",
    "        train_labels = y.iloc[train_idx]\n",
    "        neg_in_train = train_labels[train_labels == 0].index\n",
    "        pos_in_train = train_labels[train_labels == 1].index\n",
    "\n",
    "        # Move negatives to test set (they are index labels!)\n",
    "        train_idx = pos_in_train\n",
    "        # test_idx = pd.Index(index['test']).union(neg_in_train)\n",
    "        test_idx = pd.Index(index['test'])\n",
    "\n",
    "        # Convert back to positional index\n",
    "        train_pos_idx = y.index.get_indexer_for(train_idx)\n",
    "        test_pos_idx = y.index.get_indexer_for(test_idx)\n",
    "\n",
    "        # Split the data\n",
    "        print(f'\\nFold {fold}, Train size {len(train_idx)}, Test size {len(test_idx)}')\n",
    "        X_train_fold, X_val_fold = X_encoded.iloc[train_pos_idx].values, X_encoded.iloc[test_pos_idx].values\n",
    "        y_train_fold, y_val_fold = y.iloc[train_pos_idx].values, y.iloc[test_pos_idx].values\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32).to(device)\n",
    "        y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model, loss function, and optimizer\n",
    "        model = OneClassNN(X_encoded.shape[1])\n",
    "        criterion = nn.BCELoss()\n",
    "        pos_weight_value = torch.tensor([len(pos_in_train) / len(neg_in_train)], device=device)\n",
    "        # Uncomment just the Loss criterion you want to try\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_value)\n",
    "        # criterion = nn.MSELoss()  # Using MSELoss for regression-like output\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model.to(device)\n",
    "\n",
    "        # Early stopping parameters\n",
    "        best_val_AUC = 0\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Lists to store loss values\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            print(f\"Fold {fold} Epoch {epoch+1}/{epochs} Loss: {train_loss:.6f}\")\n",
    "        \n",
    "        # Validation: compute reconstruction loss for test samples\n",
    "        # model.load_state_dict(torch.load(f\"best_model_fold_{fold}.pth\"))\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                y_true.extend(y_batch.cpu().numpy())\n",
    "                y_pred.extend(outputs.cpu().numpy())\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Find best threshold using only test set (alternative: calibrate using val set)\n",
    "        thresholds = np.linspace(min(y_pred), max(y_pred), 100)\n",
    "        best_auc, best_thresh = 0, 0.5\n",
    "        for thresh in thresholds:\n",
    "            preds = (y_pred > thresh).astype(int)\n",
    "            auc = roc_auc_score(y_true, preds)\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_thresh = thresh\n",
    "\n",
    "        y_pred = (y_pred > best_thresh).astype(int)\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, average=None)\n",
    "        recall = recall_score(y_true, y_pred, average=None)\n",
    "        f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold,\n",
    "            'AUC': best_auc,\n",
    "            'Threshold': best_thresh,\n",
    "            'Precision1': precision[1],\n",
    "            'Recall1': recall[1],\n",
    "            'F1_1': f1[1],\n",
    "            'Precision0': precision[0],\n",
    "            'Recall0': recall[0],\n",
    "            'F1_0': f1[0],\n",
    "            'ConfusionMatrixTN': conf_matrix[0][0],\n",
    "            'ConfusionMatrixFP': conf_matrix[0][1],\n",
    "            'ConfusionMatrixFN': conf_matrix[1][0],\n",
    "            'ConfusionMatrixTP': conf_matrix[1][1],\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y_true\n",
    "        })\n",
    "\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        # print(f\"Best AUC: {best_auc:.4f} at threshold {best_thresh:.4f}\")\n",
    "        print(f'Confusion matrix: \\n{conf_matrix}')\n",
    "\n",
    "        overall_auc = roc_auc_score(all_y_true, all_y_pred)\n",
    "        print(f\"\\ROC AUC: {overall_auc:.4f}\")\n",
    "        print(f'Confusion matrix: \\n{conf_matrix}')\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.plot(train_losses, label='Train Loss')\n",
    "        # plt.plot(val_losses, label='Validation Loss')\n",
    "        # plt.xlabel('Epochs')\n",
    "        # plt.ylabel('Loss')\n",
    "        # plt.title(f'Training and Validation Loss Fold {fold}')\n",
    "        # plt.legend()\n",
    "        # plt.savefig(f'fold_plots/training_validation_loss_fold_{fold}.pdf')\n",
    "        # # plt.show()\n",
    "\n",
    "        # # print(classification_report(y_true_binary, y_pred_binary))\n",
    "\n",
    "\n",
    "    # Final metrics\n",
    "    overall_auc = roc_auc_score(all_y_true, all_y_pred)\n",
    "    print(f\"Final ROC AUC: {overall_auc:.4f}\")\n",
    "\n",
    "    # Plot final ROC curve\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for fold_data in fold_metrics:\n",
    "        fpr, tpr, _ = roc_curve(fold_data['y_true'], fold_data['y_pred'])\n",
    "        plt.plot(fpr, tpr, label=f\"Fold {fold_data['Fold']} AUC = {fold_data['AUC']:.4f}\")\n",
    "    # plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
    "    plt.xlabel(\"False Positive Rate (Positive label: 1)\")\n",
    "    plt.ylabel(\"True Positive Rate (Positive label: 1)\")\n",
    "    plt.title(\"ROC Curves Across Folds\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"fold_plots/roc_cv_OCC_DeepNN_kfold.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    metrics_df = pd.DataFrame(fold_metrics)\n",
    "    metrics_df.drop(columns=['y_pred', 'y_true'], inplace=True)\n",
    "    metrics_df.to_csv(\"fold_plots/OCC_Metric_Summary.csv\", index=False)\n",
    "    print(\"\\nPer-fold metrics saved to 'OCC_Metric_Summary.csv'\")\n",
    "\n",
    "    return model, fold_metrics, metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate, and test the model\n",
    "model, main_metrics_result, standard_metrics = train_validate_test_model(cross_val_folds, X_encoded, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a12425",
   "metadata": {},
   "source": [
    "## 4. Statistical tests for comparing RandomForest and Deep Leaning model across all folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963dd3e",
   "metadata": {},
   "source": [
    "### 4.1 Statisitical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View metrics\n",
    "rf_metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View metrics\n",
    "standard_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba892dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "# Example AUC scores from 10-fold cross-validation for two algorithms\n",
    "auc_algorithm_rf = rf_metrics_summary['AUC'].to_numpy()\n",
    "auc_algorithm_occ = standard_metrics['AUC'].to_numpy()\n",
    "\n",
    "# Perform paired t-test\n",
    "t_stat, p_value_ttest = ttest_rel(auc_algorithm_rf, auc_algorithm_occ)\n",
    "\n",
    "# Perform Wilcoxon signed-rank test\n",
    "w_stat, p_value_wilcoxon = wilcoxon(auc_algorithm_rf, auc_algorithm_occ)\n",
    "\n",
    "# Print results\n",
    "print(f\"Paired t-test: t-statistic = {t_stat:.4f}, p-value = {p_value_ttest:.4f}\")\n",
    "print(f\"Wilcoxon signed-rank test: w-statistic = {w_stat:.4f}, p-value = {p_value_wilcoxon:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value_ttest < alpha:\n",
    "    print(\"Paired t-test: There is a significant difference between the AUC scores of the two algorithms.\")\n",
    "else:\n",
    "    print(\"Paired t-test: There is no significant difference between the AUC scores of the two algorithms.\")\n",
    "\n",
    "if p_value_wilcoxon < alpha:\n",
    "    print(\"Wilcoxon signed-rank test: There is a significant difference between the AUC scores of the two algorithms.\")\n",
    "else:\n",
    "    print(\"Wilcoxon signed-rank test: There is no significant difference between the AUC scores of the two algorithms.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a96188",
   "metadata": {},
   "source": [
    "### 4.2 Mean AUC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1978981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate statistics for RandomForest\n",
    "rf_mean = np.mean(rf_metrics_summary['AUC'])\n",
    "rf_median = np.median(rf_metrics_summary['AUC'])\n",
    "rf_min = np.min(rf_metrics_summary['AUC'])\n",
    "rf_max = np.max(rf_metrics_summary['AUC'])\n",
    "rf_q1 = np.percentile(rf_metrics_summary['AUC'], 25)\n",
    "rf_q3 = np.percentile(rf_metrics_summary['AUC'], 75)\n",
    "\n",
    "# Calculate statistics for Deep Neural Network for OCC\n",
    "occ_mean = np.mean(standard_metrics['AUC'])\n",
    "occ_median = np.median(standard_metrics['AUC'])\n",
    "occ_min = np.min(standard_metrics['AUC'])\n",
    "occ_max = np.max(standard_metrics['AUC'])\n",
    "occ_q1 = np.percentile(standard_metrics['AUC'], 25)\n",
    "occ_q3 = np.percentile(standard_metrics['AUC'], 75)\n",
    "\n",
    "data = {\n",
    "    'Fold': list(range(1, 11)),\n",
    "    'RandomForest': auc_algorithm_rf,\n",
    "    'Deep Neural Network for OCC': auc_algorithm_occ\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting the boxplots\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = df[['RandomForest', 'Deep Neural Network for OCC']].boxplot()\n",
    "\n",
    "# Annotate statistics for RandomForest\n",
    "plt.text(1.1, rf_mean, f'Mean: {rf_mean:.4f}', horizontalalignment='center', color='blue')\n",
    "plt.text(1.1, rf_median, f'Median: {rf_median:.4f}', horizontalalignment='center', color='green')\n",
    "plt.text(1.1, rf_min, f'Min: {rf_min:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(1.1, rf_max, f'Max: {rf_max:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(1.1, rf_q1, f'Q1: {rf_q1:.4f}', horizontalalignment='center', color='purple')\n",
    "plt.text(1.1, rf_q3, f'Q3: {rf_q3:.4f}', horizontalalignment='center', color='purple')\n",
    "\n",
    "# Annotate statistics for Deep Neural Network for OCC\n",
    "plt.text(2.1, occ_mean, f'Mean: {occ_mean:.4f}', horizontalalignment='center', color='blue')\n",
    "plt.text(2.1, occ_median, f'Median: {occ_median:.4f}', horizontalalignment='center', color='green')\n",
    "plt.text(2.1, occ_min, f'Min: {occ_min:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(2.1, occ_max, f'Max: {occ_max:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(2.1, occ_q1, f'Q1: {occ_q1:.4f}', horizontalalignment='center', color='purple')\n",
    "plt.text(2.1, occ_q3, f'Q3: {occ_q3:.4f}', horizontalalignment='center', color='purple')\n",
    "\n",
    "plt.title('AUC Scores Comparison Across 10 Folds')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244ef83",
   "metadata": {},
   "source": [
    "## 5. Interpretability of the RandomForest using SHAP values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea635e",
   "metadata": {},
   "source": [
    "### 5.1 Train again RandomForest with the entire dataset to compute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_RF_model = rf_biotech.fit(X_encoded, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55b901",
   "metadata": {},
   "source": [
    "### 5.2 Plot graphbars with each varaible contribution to the decision of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the feature importance\n",
    "importances = full_RF_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the importance \n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_encoded.columns,\n",
    "    'Contribution': importances\n",
    "})\n",
    "\n",
    "# Create mapping to original columns to retrieve the original encoded features\n",
    "importance_mapping = {}\n",
    "for orig_col in columnas_categorical:\n",
    "    importance_mapping[orig_col] = feature_importance_df[\n",
    "        feature_importance_df['Feature'].str.startswith(orig_col)\n",
    "    ]['Contribution'].sum()\n",
    "\n",
    "for num_col in columnas_numerical:\n",
    "    importance_mapping[num_col] = feature_importance_df[\n",
    "        feature_importance_df['Feature'] == num_col\n",
    "    ]['Contribution'].values[0]\n",
    "\n",
    "# Create final importance dataframe\n",
    "final_importance = pd.DataFrame(\n",
    "    importance_mapping.items(),\n",
    "    columns=['Feature', 'Contribution']\n",
    ").sort_values('Contribution', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Original Columns):\")\n",
    "print(final_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "number = 50\n",
    "sns.barplot(x='Contribution', y='Feature', data=final_importance.head(number))\n",
    "\n",
    "for index, value in enumerate(final_importance.head(number)['Contribution']):\n",
    "    plt.text(value, index, f'{value:.4f}', va='center')\n",
    "\n",
    "plt.title(f'Top Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549ba42",
   "metadata": {},
   "source": [
    "### 5.3 SHAP values and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e89290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP values of the 0.1% (~= 300 records) of the dataset and the RandomForest turning back to the initial variables before OneHotEncoding\n",
    "sample_size = int(0.001 * len(X_encoded))\n",
    "X_sample = X_encoded.sample(n=sample_size, random_state=42)\n",
    "# Create a SHAP TreeExplainer for the Random Forest\n",
    "explainer = shap.TreeExplainer(full_RF_model)\n",
    "# shap_values = explainer.shap_values(X_sample, approximate=True)\n",
    "shap_values = explainer.shap_values(X_sample, approximate=True)\n",
    "# Plot SHAP summary plot for class 1 (positive class)\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")  # use plot_type=\"dot\" for the classic beeswarm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expla_train, X_expla, y_expla_train, y_expla = train_test_split(X_encoded, y, test_size=0.001, stratify=y, random_state=42)\n",
    "Counter(y_expla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778394e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(full_RF_model.predict, \n",
    "                           masker=shap.maskers.Independent(X_expla),\n",
    "                           max_display=15)\n",
    "explainer.feature_names = X_expla.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85760c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular SHAP values para los datos X_val\n",
    "shap_values = explainer(X_expla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "def format_func(value, tick_number):\n",
    "    return f'{value:.2f}'\n",
    "# Bar plot\n",
    "shap.plots.bar(shap_values, max_display=10, show=False)\n",
    "plt.title(\"Características Más Importantes\")\n",
    "# plt.gca().yaxis.set_major_formatter(FuncFormatter(format_func))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32021fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm\n",
    "# Visualizar las características más importantes para todas las instancias\n",
    "shap.plots.beeswarm(shap_values, max_display=15, show=False)\n",
    "plt.title(\"Características Más Importantes\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc193675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a force plot\n",
    "\n",
    "shap.plots.force(shap_values[0], show=False, matplotlib=True)\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "plt.title(\"Force plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot\n",
    "instance = 10\n",
    "shap.plots.waterfall(shap_values[instance], max_display=15, show=False)\n",
    "plt.title(\"SHAP Values para la Instancia {}\".format(instance))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7867870",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "feature_index = 2\n",
    "feature_name = shap_values.feature_names[feature_index]\n",
    "shap.plots.scatter(shap_values[:, feature_name], color=shap_values, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24e137",
   "metadata": {},
   "source": [
    "## 6. Factor Analysis of Mixed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428c9b0",
   "metadata": {},
   "source": [
    "### 6.1 FAMD with the initial dataset with mixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prince\n",
    "\n",
    "# Sample 50% of the dataset and separate independent and dependent variables.\n",
    "# sample_df = bio_df.sample(frac=0.5)\n",
    "sample_df = df_clean_shuffled.sample(frac=0.5)\n",
    "X = sample_df.drop(columns=['Assigned'])\n",
    "y = sample_df['Assigned']\n",
    "\n",
    "# Apply FAMD with 5 components to determine the ideal number of components using the elbow method in the scree plot\n",
    "# or the Cumulative Explaned Variance between 70% and 90%\n",
    "# famd = prince.FAMD(n_components=5, random_state=42)\n",
    "# Apply FAMD with the ideal number of components\n",
    "famd = prince.FAMD(n_components=3, random_state=42)\n",
    "famd = famd.fit(X)\n",
    "X_famd = famd.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba632ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "famd.scree_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute explained inertia manually\n",
    "U, s, V = np.linalg.svd(famd.row_coordinates(X), full_matrices=False)\n",
    "explained_inertia = (s ** 2) / np.sum(s ** 2)\n",
    "\n",
    "# Print explained inertia for each component\n",
    "for i, inertia in enumerate(explained_inertia, start=1):\n",
    "    print(f\"Component {i}: {inertia:.4f} (Explained Variance)\")\n",
    "\n",
    "# Cumulative explained inertia\n",
    "cumulative_inertia = np.cumsum(explained_inertia) * 100\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "for i, cum_inertia in enumerate(cumulative_inertia, start=1):\n",
    "    print(f\"Component {i}: {cum_inertia:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot cummulative Variance\n",
    "plt.plot(range(1, len(cumulative_inertia) + 1), cumulative_inertia, marker='o', \n",
    "         linestyle='--', color='b', label='Cummulative Explained Variance')\n",
    "# Plot individual Variance\n",
    "plt.plot(range(1, len(explained_inertia) + 1), explained_inertia * 100, marker='^', \n",
    "         linestyle='--', color='r', label='Explained Variance')\n",
    "# Annotate cummulative Variance\n",
    "for idx, item in enumerate(cumulative_inertia):\n",
    "    plt.text(idx+1.3, item, f'{item:.2f}', horizontalalignment='right', color='blue')\n",
    "# Annotate Explained Variance\n",
    "for idx, variance in enumerate(explained_inertia):\n",
    "    plt.text(idx+1, variance * 100, f'{(variance*100):.2f}', horizontalalignment='left', verticalalignment='top', color='r')\n",
    "plt.title('Explained Variance & Cumulative Explained Variance by FAMD Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.axhline(y=70, color='black', linestyle='--', label='70% Variance')\n",
    "plt.axhline(y=90, color='black', linestyle='--', label='90% Variance')\n",
    "plt.xticks(range(1, len(cumulative_inertia) + 1))\n",
    "plt.yticks(range(0, 110, 10))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates (loadings) for categorical variable levels\n",
    "categorical_coords = famd.column_coordinates_\n",
    "# categorical_coords.index.name = 'variable'\n",
    "categorical_coords.rename(columns={0:'Component1', 1:'Component2', 2:'Component3', 3:'Component4', 4:'Component5'}, \n",
    "                          inplace=True)\n",
    "\n",
    "# Compute correlations for numerical variables\n",
    "numerical_corrs = []\n",
    "for i in range(X_famd.shape[1]):\n",
    "    component = X_famd.iloc[:, i]\n",
    "    corr = X[columnas_numerical].corrwith(component)\n",
    "    numerical_corrs.append(corr)\n",
    "\n",
    "# Convert to DataFrame with same shape as categorical_coords\n",
    "numerical_corrs_df = pd.concat(numerical_corrs, axis=1)\n",
    "numerical_corrs_df.columns = categorical_coords.columns  # Match FAMD component names\n",
    "numerical_corrs_df.index.name = 'variable'\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "# combined_contributions = categorical_coords.merge(how='left', right=numerical_corrs_df, on='variable')\n",
    "combined_contributions = categorical_coords\n",
    "combined_contributions.update(numerical_corrs_df)\n",
    "\n",
    "# # Optional: sort for better visualization\n",
    "# combined_contributions = combined_contributions.sort_index()\n",
    "\n",
    "# Display result\n",
    "print(combined_contributions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18184ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square the correlations to get contribution approximation\n",
    "contrib = combined_contributions ** 2\n",
    "contrib_norm_df = contrib.div(contrib.sum(axis=0), axis=1) * 100  # Normalize to get % contribution\n",
    "# top_contrib = contrib_norm_df.apply(lambda x: x.sort_values(ascending=False).head(29))\n",
    "for col in contrib_norm_df.columns:\n",
    "    top_contrib = contrib_norm_df.sort_values(ascending=False, by=col)\n",
    "    print(top_contrib[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index so 'variable' becomes a column\n",
    "df_melted = contrib_norm_df.reset_index().melt(id_vars='variable', \n",
    "                                                var_name='Component', \n",
    "                                                value_name='Contribution')\n",
    "df_melted.rename(columns={'variable': 'Variable'}, inplace=True)\n",
    "\n",
    "# Sort variables by average contribution across components (optional, for visual clarity)\n",
    "df_melted['Variable'] = pd.Categorical(\n",
    "    df_melted['Variable'],\n",
    "    categories=(contrib_norm_df.mean(axis=1)\n",
    "                .sort_values(ascending=False)\n",
    "                .index.tolist()),\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Set the color palette for the components\n",
    "palette = sns.color_palette(n_colors=contrib_norm_df.shape[1])\n",
    "\n",
    "# Create the barplot\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(\n",
    "    data=df_melted,\n",
    "    x='Variable',\n",
    "    y='Contribution',\n",
    "    hue='Component',\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "plt.xticks(rotation=90, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylabel('Contribution (%)', fontsize=18)\n",
    "plt.xlabel('Variable', fontsize=18)\n",
    "plt.title('Variable Contributions to FAMD Components', fontsize=20)\n",
    "plt.legend(title='Component', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4048873",
   "metadata": {},
   "source": [
    "### 6.2 PCA with the encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2142714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prince\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select randomly 60% of the dataset\n",
    "X_sample_full = X_encoded.copy()\n",
    "X_sample_full['Assigned'] = y\n",
    "X_sample = X_sample_full.sample(frac=1.0)\n",
    "y_sample = X_sample['Assigned']\n",
    "X_sample.drop(columns=['Assigned'], inplace=True)\n",
    "del X_sample_full\n",
    "\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_pca = pca.fit_transform(X_sample)\n",
    "\n",
    "# Scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, 'o-', color='blue')\n",
    "plt.title('Scree Plot (PCA)')\n",
    "plt.xlabel('Component Number')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Individual factor map\n",
    "individuals = pd.DataFrame(X_pca, columns=[f'F{i+1}' for i in range(pca.n_components)])\n",
    "individuals['DependentBoolean'] = y_sample.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=individuals, x='F1', y='F2', hue='DependentBoolean', palette='viridis')\n",
    "plt.title('Individual Factor Map (F1 vs F2)')\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('F2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "plt.title('Cumulative Explained Variance by PCA Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.7, color='r', linestyle='--', label='70% Variance')\n",
    "plt.axhline(y=0.9, color='g', linestyle='--', label='90% Variance')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a601e9",
   "metadata": {},
   "source": [
    "### 6.3 Statistical comparison between the 50% sample for FAMD and the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance, ks_2samp, entropy\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78300f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fuction to compare distributions of a variable between the entire dataset and a 50% subsample.\n",
    "   It calculates Wasserstein's distance for numeric variables and Jensen-Shannon distance for categorical variables.\n",
    "   It also plots the distributions if plot=True.\n",
    "   Parameters:\n",
    "   - population: DataFrame containing the entire dataset.\n",
    "   - sample: DataFrame containing the 50% subsample.\n",
    "   - variable: The name of the variable to compare.\n",
    "   - plot: Boolean indicating whether to plot the distributions (default is True).\n",
    "   - KS test assume two-sided with nule hypothesis that the two distributions are the same, and alternative that they are different.\n",
    "   Returns:\n",
    "   - A dictionary with the calculated distances and statistics.'''\n",
    "def compare_distributions(population, sample, variable, plot=True):\n",
    "    pop_data = population[variable]\n",
    "    samp_data = sample[variable]\n",
    "    \n",
    "    if pop_data.dtype.kind in 'fi':  # Numeric variable\n",
    "        # Distance metrics\n",
    "        ws_dist = wasserstein_distance(pop_data, samp_data)\n",
    "        ks_stat, ks_pval = ks_2samp(pop_data, samp_data, method='auto', alternative='two-sided')\n",
    "        \n",
    "        print(f\"Numeric variables comparison: {variable}\")\n",
    "        print(f\"- Wasserstein's distance: {ws_dist:.4f}\")\n",
    "        print(f\"- KS Statistic: {ks_stat:.4f} (p-value: {ks_pval:.4f})\")\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.kdeplot(pop_data, label='Entire dataset', bw_adjust=0.5)\n",
    "            sns.kdeplot(samp_data, label='Subsample 50%', bw_adjust=0.5)\n",
    "            plt.title(f'Distribution of {variable}')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        return {'Wasserstein': ws_dist, 'KS_stat': ks_stat, 'KS_pval': ks_pval}, 'numeric'\n",
    "    \n",
    "    else:  # Categorical variables\n",
    "        # Compute relative frequencies\n",
    "        pop_counts = pop_data.value_counts(normalize=True).sort_index()\n",
    "        samp_counts = samp_data.value_counts(normalize=True).sort_index()\n",
    "        \n",
    "        # Assure all categories are present in both distributions\n",
    "        all_cats = set(pop_counts.index).union(set(samp_counts.index))\n",
    "        pop_counts = pop_counts.reindex(all_cats, fill_value=0)\n",
    "        samp_counts = samp_counts.reindex(all_cats, fill_value=0)\n",
    "        \n",
    "        # Distance metrics\n",
    "        js_dist = jensenshannon(pop_counts, samp_counts, base=2)\n",
    "        kl_div = entropy(pop_counts, samp_counts)\n",
    "        \n",
    "        print(f\"Comparison between categorical variables: {variable}\")\n",
    "        print(f\"- Jensen-Shannon distance: {js_dist:.4f}\")\n",
    "        print(f\"- KL Divergency: {kl_div:.4f}\")\n",
    "        \n",
    "        if plot:\n",
    "            if variable in ['Subject', 'Sub', 'Name']:\n",
    "                kind = 'barh'  \n",
    "                heigh = 68 if variable == 'Subject' else 24\n",
    "                width = 8\n",
    "            else:\n",
    "                kind = 'bar'  \n",
    "                heigh = 5\n",
    "                width = 10 \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(width, heigh))\n",
    "            pop_counts.plot(kind=kind, ax=ax1, title=f'Entire dataset - {variable}')\n",
    "            samp_counts.plot(kind=kind, ax=ax2, title=f'Subsample 50% - {variable}')\n",
    "            if variable in ['Subject', 'Sub', 'Name']:\n",
    "                ax2.yaxis.set_visible(False)\n",
    "            else:\n",
    "                ax2.yaxis.set_visible(True)\n",
    "            # plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        return {'Jensen-Shannon': js_dist, 'KL_divergency': kl_div}, 'categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e70157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all variables in the dataset depending o their type (categorical or numerical)\n",
    "comparison_numerical = {}\n",
    "comparison_categorical = {}\n",
    "for var in X.columns:\n",
    "    result, type = compare_distributions(df_clean_shuffled, sample_df, var)\n",
    "    if type == 'numeric':\n",
    "        comparison_numerical[var] = result\n",
    "    else:\n",
    "        comparison_categorical[var] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a11262",
   "metadata": {},
   "source": [
    "**Comments on the statisitical results**\n",
    "\n",
    "> All numerical variables show for the KS test\n",
    ">> $p-value >> 0.05$\n",
    ">> \n",
    ">> $KS\\_statistic < 0.003$\n",
    ">> \n",
    ">> $Wasserstein\\_distance < 0.03$\n",
    ">\n",
    "> These results strongly supports the null hypothesis that the two distributions are identical. \n",
    ">\n",
    "> There is no meaningful difference between the distributions in the sample an the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_results = pd.DataFrame(comparison_numerical).T\n",
    "numeric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90478da1",
   "metadata": {},
   "source": [
    "**Comments on the statisitical results**\n",
    "\n",
    "> All categorical variables show\n",
    ">> $Jensen\\_Shannon\\_distance < 0.02$\n",
    ">> \n",
    ">> $KL\\_divergency < 0.0002$\n",
    ">\n",
    "> These results strongly supports that the two distributions are identical. \n",
    ">\n",
    "> There is no meaningful difference between the distributions in the sample an the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_results = pd.DataFrame(comparison_categorical).T\n",
    "categorical_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

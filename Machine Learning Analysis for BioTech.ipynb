{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef37655",
   "metadata": {},
   "source": [
    "# Machine Learning analysis of data about Competency Assessment of Students from HE Biotech Academic Programs\n",
    "\n",
    "**Index**\n",
    ">\n",
    "> 1. [Data loading and preparation for Machine Learning for Stratified 10-fold Cross-Validation.](#1-data-loading-and-preparation-for-machine-learning-for-stratified-10-fold-cross-validation)\n",
    ">\n",
    "> 2. [Random Forest definition, training, and validation.](#2-random-forest-definition-training-and-validation)\n",
    ">\n",
    "> 3. [Deep Learning neural network for one-class classification with Pytorch, definition, training, and validation.](#3-deep-learning-neural-network-for-one-class-classification-with-pytorch-definition-training-and-validation)\n",
    ">\n",
    "> 4. [Statistical tests for comparing RandomForest and Deep Leaning model across all folds](#4-statistical-tests-for-comparing-randomforest-and-deep-leaning-model-across-all-folds)\n",
    ">\n",
    "> 5. [Interpretability of the RandomForest using SHAP values](#5-interpretability-of-the-randomforest-using-shap-values)\n",
    ">\n",
    "> 6. [PCA and FAMD analysis](#6-factor-analysis-of-mixed-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, RocCurveDisplay\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, \\\n",
    "    precision_score, recall_score, f1_score, classification_report, precision_score, \\\n",
    "    precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12382a45",
   "metadata": {},
   "source": [
    "## 1. Data loading and preparation for Machine Learning for Stratified 10-fold Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe and showing some information\n",
    "bio_df = pd.read_csv('sourcecode/EICData/Bio_students_v5.6.csv')\n",
    "bio_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# Remove \"ID\" column\n",
    "bio_df.drop('ID', axis=1, inplace=True) \n",
    "bio_df['last_col'] = bio_df['Assigned']\n",
    "bio_df.drop(columns=['Assigned', 'isRegular'], inplace=True)\n",
    "bio_df.rename(columns={'last_col':'Assigned'}, inplace=True)\n",
    "# There were an empty string category of the variable Modality\n",
    "bio_df['Modality'] = bio_df['Modality'].replace(r'^\\s*$', 'Unknown', regex=True)\n",
    "# Remove records with any NaN \n",
    "bio_df.dropna(inplace=True)\n",
    "bio_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding also boolean variables include=['object']\n",
    "columnas_categorical = bio_df.select_dtypes(exclude=['int64', 'float64']).columns.tolist() \n",
    "# Excluding also boolean variables\n",
    "columnas_numerical = bio_df.select_dtypes(include=['int64', 'float64']).columns.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13665022",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "# Remove class var if it is in the categorical list\n",
    "if 'Assigned' in (columnas_categorical):\n",
    "    columnas_categorical.remove('Assigned')\n",
    "# Remove class var if it is in the numeric list\n",
    "if 'Assigned' in (columnas_numerical):\n",
    "    columnas_numerical.remove('Assigned')\n",
    "\n",
    "# Encoding categorical columns\n",
    "df_clean_shuffled = bio_df.sample(frac=1)\n",
    "y = df_clean_shuffled['Assigned'].astype('int')\n",
    "\n",
    "# Encode full dataset first\n",
    "# We have avoid dropping the first category, because RandomForest is better if having all categories explicitly\n",
    "full_preprocessor = ColumnTransformer([\n",
    "    ('num', MinMaxScaler(), columnas_numerical),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', #drop='None', \n",
    "                          sparse_output=False), \n",
    "            columnas_categorical)\n",
    "])\n",
    "X_encoded = full_preprocessor.fit_transform(df_clean_shuffled)\n",
    "\n",
    "# Ensure no value is greater than 1.0\n",
    "X_encoded = np.clip(X_encoded, 0, 1)\n",
    "\n",
    "# Get feature names after encodings\n",
    "encoded_features = []\n",
    "for col in full_preprocessor.transformers_:\n",
    "    if col[0] == 'num':\n",
    "        encoded_features.extend(col[2])  # numeric columns\n",
    "    elif col[0] == 'cat':\n",
    "        # Get one-hot encoded names\n",
    "        encoder = col[1]\n",
    "        # Comment if not using drop='First'\n",
    "        encoded_features.extend([f\"{col[2][i]}_{cat}\" \n",
    "                               for i in range(len(col[2])) \n",
    "                               for cat in encoder.categories_[i]])\n",
    "        # Uncomment if using drop='First'\n",
    "        # categories = encoder.categories_\n",
    "        # for i, feature in enumerate(col[2]):\n",
    "        #     # Skip the first category if drop='first'\n",
    "        #     for cat in categories[i][1:]:\n",
    "        #         encoded_features.append(f\"{feature}_{cat}\")\n",
    "\n",
    "# Convert back to DataFrame with proper column names\n",
    "X_encoded = pd.DataFrame(X_encoded, columns=encoded_features)\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_splitter(X_encoded, y, n_splits=10):\n",
    "    #  Modficar para realizar entrenamiento del modelo con los datos de X_data\n",
    "    Train = X_encoded    \n",
    "    labels = y\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cross_val_data = skf.split(Train, labels)\n",
    "    return cross_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b52f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same cross-validation splits and codified data for both algorithms\n",
    "cross_val_idxs = cross_val_splitter(X_encoded, y, n_splits = 10)\n",
    "\n",
    "# Create a list to store each fold's data\n",
    "cross_val_folds = []\n",
    "\n",
    "# Loop through each fold and store the indices in a dictionary\n",
    "for fold, (train, test) in enumerate(cross_val_idxs):\n",
    "    fold_data = {\n",
    "        'fold': fold,\n",
    "        'train': list(train.astype('int')),\n",
    "        'test': list(test.astype('int'))\n",
    "    }\n",
    "    cross_val_folds.append(fold_data)\n",
    "\n",
    "# for fold in cross_val_folds:\n",
    "#     print(f'Train: {cross_val_folds[0]['train']}')\n",
    "#     print(f'Test {cross_val_folds[0]['test']}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0583",
   "metadata": {},
   "source": [
    "## 2. Random Forest definition, training, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b45b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Setup\n",
    "\n",
    "rf_biotech = RandomForestClassifier(\n",
    "    n_estimators=100,  # Default number of trees\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # It balance the weight for each class accoridng to the imbalance ratio\n",
    "    verbose=False,\n",
    "    n_jobs=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb83a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_cross_val_RandomForest(cross_val_idxs, X_encoded, y, rf_biotech):\n",
    "    print('Stratified 10-Fold Cross-Validation with RandomForest')\n",
    "\n",
    "    # Initialize True Positive Rate and Area Under Curve\n",
    "    os.makedirs(\"fold_plots\", exist_ok=True)\n",
    "    tprs, aucs = [], []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    # MÃ©tricas de estudio\n",
    "    metrics = {\n",
    "        'Iteration': [],\n",
    "        'AUC': [],\n",
    "        'Precision_Class0': [],\n",
    "        'Precision_Class1': [],\n",
    "        'Recall_Class0': [],\n",
    "        'Recall_Class1': [],\n",
    "        'F1_Class0': [],\n",
    "        'F1_Class1': [],\n",
    "        'ConfusionMatrix': []\n",
    "    }\n",
    "\n",
    "    # Plot ROC Curve for every Cross Validation Split\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fig, ax = plt.subplots()\n",
    "    # Use manually stratified folds to explore the entire dataset\n",
    "    # fold_size = int(len(X_encoded.index)/n_splits)\n",
    "    # for index in range(n_splits):\n",
    "    for fold in cross_val_idxs:\n",
    "        # Split the data\n",
    "        index = fold['fold']\n",
    "        train_idx = fold['train']\n",
    "        test_idx = fold['test']\n",
    "        print(f'\\nFold {index}, Train size {len(train_idx)}, Test size {len(test_idx)}')\n",
    "        X_train_fold, X_val_fold = X_encoded[train_idx], X_encoded[test_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx].values, y.iloc[test_idx].values\n",
    "        # X_train, X_test = X_encoded.iloc[train_idx], X_encoded.iloc[test_idx]\n",
    "        # y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        rf_biotech.fit(X_train_fold, y_train_fold) # This statement retrains the model from scratch\n",
    "        # model_loaded.fit(X_train, y_train) # I am affraid this statement is using the model pretrained with train data\n",
    "        # Calcular la Curva AUC\n",
    "        plot = RocCurveDisplay.from_estimator(\n",
    "            rf_biotech, X_val_fold, y_val_fold,\n",
    "            # name=\"Fold {}\".format(index),\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # Then, update the label with formatted AUC\n",
    "        plot.line_.set_label(\"Fold {} (AUC = {:.4f})\".format(index, plot.roc_auc))\n",
    "\n",
    "        # Interpolate TPR for averaging\n",
    "        interp_tpr = np.interp(mean_fpr, plot.fpr, plot.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(plot.roc_auc)\n",
    "\n",
    "        # Predecir los datos de entrenamiento\n",
    "        y_pred = rf_biotech.predict(X_val_fold)\n",
    "\n",
    "        # Guardar mÃ©tricas en un diccionario\n",
    "        metrics['Iteration'].append(index + 1)\n",
    "        metrics['AUC'].append(plot.roc_auc)\n",
    "        metrics['ConfusionMatrix'].append(confusion_matrix(y_val_fold, y_pred))\n",
    "        for cls in [0, 1]:\n",
    "            metrics[f'Precision_Class{cls}'].append(precision_score(y_val_fold, y_pred, pos_label=cls, zero_division=0))\n",
    "            metrics[f'Recall_Class{cls}'].append(recall_score(y_val_fold, y_pred, pos_label=cls, zero_division=0))\n",
    "            metrics[f'F1_Class{cls}'].append(f1_score(y_val_fold, y_pred, pos_label=cls, zero_division=0))\n",
    "    \n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        title=\"ROC Curves Across Folds\",\n",
    "    )\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"fold_plots/roc_cv_randomForest_kfold.pdf\")\n",
    "\n",
    "    # Convert to DataFrame to save it and analyze it\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv('fold_plots/RandomForest_Metric_Summary.csv', index=False)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics_summary = train_validate_cross_val_RandomForest(cross_val_folds, X_encoded, y, rf_biotech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068794b",
   "metadata": {},
   "source": [
    "## 3. Deep Learning neural network for one-class classification with Pytorch, definition, training, and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneClassNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(OneClassNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.sigmoid(self.fc6(x)) # Ensure this line is present\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86810f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train, validate, and test the model\n",
    "def train_validate_test_model(cross_val_idxs, X_encoded, y, batch_size=batch_size, epochs=100, learning_rate=0.0001, patience=10):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")       \n",
    "        \n",
    "    # Lists to store results\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    fold_auc_scores = []\n",
    "    fold_metrics = []\n",
    "    best_y_pred = []\n",
    "\n",
    "    for index in cross_val_idxs:\n",
    "        fold = index['fold']\n",
    "        train_idx = index['train']\n",
    "        test_idx = index['test']        \n",
    "        # Split the data\n",
    "        print(f'\\nFold {fold}, Train size{len(train_idx)}, Test size {len(test_idx)}')\n",
    "        X_train_fold, X_val_fold = X_encoded[train_idx], X_encoded[test_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx].values, y.iloc[test_idx].values\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32).to(device)\n",
    "        y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model, loss function, and optimizer\n",
    "        model = OneClassNN(X_encoded.shape[1])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model.to(device)\n",
    "\n",
    "        # Early stopping parameters\n",
    "        best_val_AUC = 0\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Lists to store loss values\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "        \n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    y_true.extend(y_batch.cpu().numpy())\n",
    "                    y_pred.extend(outputs.cpu().numpy())\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            epoch_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val AUC: {epoch_auc:.4f}\")\n",
    "            \n",
    "            # Early stopping check for validation_AUC\n",
    "            if epoch_auc >= best_val_AUC:\n",
    "                best_val_AUC = epoch_auc\n",
    "                best_y_pred = y_pred\n",
    "                patience_counter = 0\n",
    "                # Save the best model\n",
    "                torch.save(model.state_dict(), f'best_model_epoch{epoch}.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch} with AUC = {best_val_AUC:.4f}\")\n",
    "                    break\n",
    "            \n",
    "        # Store preformance metrics\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(best_y_pred)\n",
    "        fold_auc_scores.append(best_val_AUC)\n",
    "\n",
    "        # Adding standard metrics\n",
    "        y_pred_binary = (np.array(best_y_pred) >= 0.5).astype(int)\n",
    "        y_true_binary = np.array(y_true).astype(int)\n",
    "\n",
    "        precision = precision_score(y_true_binary, y_pred_binary, average=None)\n",
    "        recall = recall_score(y_true_binary, y_pred_binary, average=None)\n",
    "        f1 = f1_score(y_true_binary, y_pred_binary, average=None)\n",
    "\n",
    "        precision0, precision1 = precision\n",
    "        recall0, recall1 = recall\n",
    "        f1_0, f1_1 = f1\n",
    "        \n",
    "        conf_matrix = confusion_matrix(y_true_binary, y_pred_binary, labels=[0,1])\n",
    "        fold_metrics.append({\n",
    "            'Fold': fold,\n",
    "            'AUC': best_val_AUC,\n",
    "            'best_y_pred': best_y_pred,\n",
    "            'y_true': y_true,\n",
    "            'Precision1': precision1,\n",
    "            'Recall1': recall1,\n",
    "            'F1_1': f1_1,\n",
    "            'Precision0': precision0,\n",
    "            'Recall0': recall0,\n",
    "            'F1_0': f1_0,\n",
    "            'ConfusionMatrixTN': conf_matrix[0][0],\n",
    "            'ConfusionMatrixFP': conf_matrix[0][1],\n",
    "            'ConfusionMatrixFN': conf_matrix[1][0],\n",
    "            'ConfusionMatrixTP': conf_matrix[1][1]\n",
    "        })\n",
    "\n",
    "        # # Save metrics to a Pandas Dataframe\n",
    "        # metrics = pd.DataFrame({\n",
    "        #     'Fold': list(range(1, 11)),\n",
    "        #     'AUC': fold_auc_scores\n",
    "        # }).to_csv(\"fold_auc_scores.csv\", index=False)\n",
    "\n",
    "        # Plot training and validation loss\n",
    "        plt.figure()\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Training and Validation Loss Fold {fold}')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'fold_plots/training_validation_loss_fold_{fold}.pdf')\n",
    "        # plt.show()\n",
    "\n",
    "        print(classification_report(y_true_binary, y_pred_binary))\n",
    "\n",
    "\n",
    "    # Final metrics\n",
    "    overall_auc = roc_auc_score(all_y_true, all_y_pred)\n",
    "    print(f\"\\nAverage AUC across folds: {np.mean(fold_auc_scores):.4f}\")\n",
    "    print(f\"Final ROC AUC: {overall_auc:.4f}\")\n",
    "\n",
    "    # Plot final ROC curve\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for fold_data in fold_metrics:\n",
    "        fpr, tpr, _ = roc_curve(fold_data['y_true'], fold_data['best_y_pred'])\n",
    "        plt.plot(fpr, tpr, label=f\"Fold {fold_data['Fold']} AUC = {fold_data['AUC']:.4f}\")\n",
    "    # plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
    "    plt.xlabel(\"False Positive Rate (Positive label: 1)\")\n",
    "    plt.ylabel(\"True Positive Rate (Positive label: 1)\")\n",
    "    plt.title(\"ROC Curves Across Folds\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"fold_plots/final_roc_curves.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    metrics_df = pd.DataFrame(fold_metrics)\n",
    "    metrics_df.drop(columns=['best_y_pred', 'y_true'], inplace=True)\n",
    "    metrics_df.to_csv(\"fold_plots/OCC_Metric_Summary.csv\", index=False)\n",
    "    print(\"\\nPer-fold metrics saved to 'OCC_Metric_Summary.csv'\")\n",
    "\n",
    "    return model, fold_metrics, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate, and test the model\n",
    "model, main_metrics_result, standard_metrics = train_validate_test_model(cross_val_folds, X_encoded, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a12425",
   "metadata": {},
   "source": [
    "### 4. Statistical tests for comparing RandomForest and Deep Leaning model across all folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963dd3e",
   "metadata": {},
   "source": [
    "#### 4.1 Statisitical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View metrics\n",
    "rf_metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View metrics\n",
    "standard_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba892dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "# Example AUC scores from 10-fold cross-validation for two algorithms\n",
    "auc_algorithm_rf = rf_metrics_summary['AUC'].to_numpy()\n",
    "auc_algorithm_occ = standard_metrics['AUC'].to_numpy()\n",
    "\n",
    "# Perform paired t-test\n",
    "t_stat, p_value_ttest = ttest_rel(auc_algorithm_rf, auc_algorithm_occ)\n",
    "\n",
    "# Perform Wilcoxon signed-rank test\n",
    "w_stat, p_value_wilcoxon = wilcoxon(auc_algorithm_rf, auc_algorithm_occ)\n",
    "\n",
    "# Print results\n",
    "print(f\"Paired t-test: t-statistic = {t_stat:.4f}, p-value = {p_value_ttest:.4f}\")\n",
    "print(f\"Wilcoxon signed-rank test: w-statistic = {w_stat:.4f}, p-value = {p_value_wilcoxon:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value_ttest < alpha:\n",
    "    print(\"Paired t-test: There is a significant difference between the AUC scores of the two algorithms.\")\n",
    "else:\n",
    "    print(\"Paired t-test: There is no significant difference between the AUC scores of the two algorithms.\")\n",
    "\n",
    "if p_value_wilcoxon < alpha:\n",
    "    print(\"Wilcoxon signed-rank test: There is a significant difference between the AUC scores of the two algorithms.\")\n",
    "else:\n",
    "    print(\"Wilcoxon signed-rank test: There is no significant difference between the AUC scores of the two algorithms.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a96188",
   "metadata": {},
   "source": [
    "#### 4.2 Mean AUC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1978981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate statistics for RandomForest\n",
    "rf_mean = np.mean(rf_metrics_summary['AUC'])\n",
    "rf_median = np.median(rf_metrics_summary['AUC'])\n",
    "rf_min = np.min(rf_metrics_summary['AUC'])\n",
    "rf_max = np.max(rf_metrics_summary['AUC'])\n",
    "rf_q1 = np.percentile(rf_metrics_summary['AUC'], 25)\n",
    "rf_q3 = np.percentile(rf_metrics_summary['AUC'], 75)\n",
    "\n",
    "# Calculate statistics for Deep Neural Network for OCC\n",
    "occ_mean = np.mean(standard_metrics['AUC'])\n",
    "occ_median = np.median(standard_metrics['AUC'])\n",
    "occ_min = np.min(standard_metrics['AUC'])\n",
    "occ_max = np.max(standard_metrics['AUC'])\n",
    "occ_q1 = np.percentile(standard_metrics['AUC'], 25)\n",
    "occ_q3 = np.percentile(standard_metrics['AUC'], 75)\n",
    "\n",
    "data = {\n",
    "    'Fold': list(range(1, 11)),\n",
    "    'RandomForest': auc_algorithm_rf,\n",
    "    'Deep Neural Network for OCC': auc_algorithm_occ\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting the boxplots\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = df[['RandomForest', 'Deep Neural Network for OCC']].boxplot()\n",
    "\n",
    "# Annotate statistics for RandomForest\n",
    "plt.text(1.1, rf_mean, f'Mean: {rf_mean:.4f}', horizontalalignment='center', color='blue')\n",
    "plt.text(1.1, rf_median, f'Median: {rf_median:.4f}', horizontalalignment='center', color='green')\n",
    "plt.text(1.1, rf_min, f'Min: {rf_min:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(1.1, rf_max, f'Max: {rf_max:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(1.1, rf_q1, f'Q1: {rf_q1:.4f}', horizontalalignment='center', color='purple')\n",
    "plt.text(1.1, rf_q3, f'Q3: {rf_q3:.4f}', horizontalalignment='center', color='purple')\n",
    "\n",
    "# Annotate statistics for Deep Neural Network for OCC\n",
    "plt.text(2.1, occ_mean, f'Mean: {occ_mean:.4f}', horizontalalignment='center', color='blue')\n",
    "plt.text(2.1, occ_median, f'Median: {occ_median:.4f}', horizontalalignment='center', color='green')\n",
    "plt.text(2.1, occ_min, f'Min: {occ_min:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(2.1, occ_max, f'Max: {occ_max:.4f}', horizontalalignment='center', color='red')\n",
    "plt.text(2.1, occ_q1, f'Q1: {occ_q1:.4f}', horizontalalignment='center', color='purple')\n",
    "plt.text(2.1, occ_q3, f'Q3: {occ_q3:.4f}', horizontalalignment='center', color='purple')\n",
    "\n",
    "plt.title('AUC Scores Comparison Across 10 Folds')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244ef83",
   "metadata": {},
   "source": [
    "## 5. Interpretability of the RandomForest using SHAP values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea635e",
   "metadata": {},
   "source": [
    "### 5.1 Train again RandomForest with the entire dataset to compute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_RF_model = rf_biotech.fit(X_encoded, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55b901",
   "metadata": {},
   "source": [
    "### 5.2 Plot graphbars with each varaible contribution to the decision of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the feature importance\n",
    "importances = full_RF_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the importance \n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_encoded.columns,\n",
    "    'Contribution': importances\n",
    "})\n",
    "\n",
    "# Create mapping to original columns to retrieve the original encoded features\n",
    "importance_mapping = {}\n",
    "for orig_col in columnas_categorical:\n",
    "    importance_mapping[orig_col] = feature_importance_df[\n",
    "        feature_importance_df['Feature'].str.startswith(orig_col)\n",
    "    ]['Contribution'].sum()\n",
    "\n",
    "for num_col in columnas_numerical:\n",
    "    importance_mapping[num_col] = feature_importance_df[\n",
    "        feature_importance_df['Feature'] == num_col\n",
    "    ]['Contribution'].values[0]\n",
    "\n",
    "# Create final importance dataframe\n",
    "final_importance = pd.DataFrame(\n",
    "    importance_mapping.items(),\n",
    "    columns=['Feature', 'Contribution']\n",
    ").sort_values('Contribution', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Original Columns):\")\n",
    "print(final_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "number = 50\n",
    "sns.barplot(x='Contribution', y='Feature', data=final_importance.head(number))\n",
    "\n",
    "for index, value in enumerate(final_importance.head(number)['Contribution']):\n",
    "    plt.text(value, index, f'{value:.4f}', va='center')\n",
    "\n",
    "plt.title(f'Top Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549ba42",
   "metadata": {},
   "source": [
    "### 5.3 SHAP values and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e89290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 1% of the training data for SHAP explanation\n",
    "sample_size = int(0.01 * len(X_encoded))\n",
    "X_sample = X_encoded.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Create a SHAP TreeExplainer for the Random Forest\n",
    "explainer = shap.TreeExplainer(full_RF_model)\n",
    "\n",
    "# Compute SHAP values for the 1% sample\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# Plot SHAP summary plot for class 1 (positive class)\n",
    "shap.summary_plot(shap_values[1], X_sample, plot_type=\"bar\")  # use plot_type=\"dot\" for the classic beeswarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db66858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP values of the 1% of the dataset and the RandomForest turning back to the initial variables before OneHotEncoding.\n",
    "# Sample 1% of the encoded dataset\n",
    "sample_size = int(0.01 * len(X_encoded))\n",
    "X_sample = X_encoded.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.TreeExplainer(full_RF_model)\n",
    "shap_values = explainer.shap_values(X_sample)[1] # For class 1\n",
    "\n",
    "# Create a mapping from encoded columns to original features\n",
    "encoded_columns = X_encoded.columns\n",
    "original_columns = bio_df.columns\n",
    "\n",
    "# Example: {'gender_Male': 'gender', 'gender_Female': 'gender', 'age': 'age'}\n",
    "encoded_to_original = {}\n",
    "for col in original_columns:\n",
    "    if bio_df[col].dtype == 'object' or bio_df[col].dtype.name == 'category':\n",
    "        for val in bio_df[col].unique():\n",
    "            encoded_col = f\"{col}_{val}\"\n",
    "            if encoded_col in encoded_columns:\n",
    "                encoded_to_original[encoded_col] = col\n",
    "    else:\n",
    "        if col in encoded_columns:\n",
    "            encoded_to_original[col] = col\n",
    "\n",
    "# Aggregate SHAP values by original feature\n",
    "aggregated_shap = pd.DataFrame(index=X_sample.index)\n",
    "for original_feature in original_columns:\n",
    "    matching_encoded = [col for col, orig in encoded_to_original.items() if orig == original_feature]\n",
    "    aggregated_shap[original_feature] = shap_values[:, [encoded_columns.get_loc(col) for col in matching_encoded]].sum(axis=1)\n",
    "\n",
    "# Plot the summary\n",
    "shap.summary_plot(aggregated_shap.values, features=aggregated_shap, feature_names=aggregated_shap.columns, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24e137",
   "metadata": {},
   "source": [
    "## 6. Factor Analysis of Mixed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428c9b0",
   "metadata": {},
   "source": [
    "### 6.1 FAMD with the initial dataset with mixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prince\n",
    "\n",
    "# Sample 50% of the dataset and separate independent and dependent variables.\n",
    "sample_df = bio_df.sample(frac=0.5)\n",
    "X = sample_df.drop(columns=['Assigned'])\n",
    "y = sample_df['Assigned']\n",
    "\n",
    "# Apply FAMD with 5 components to determine the ideal number of components using the elbow method in the scree plot\n",
    "# or the Cumulative Explaned Variance between 70% and 90%\n",
    "# famd = prince.FAMD(n_components=5, random_state=42)\n",
    "# Apply FAMD with the ideal number of components\n",
    "famd = prince.FAMD(n_components=3, random_state=42)\n",
    "famd = famd.fit(X)\n",
    "X_famd = famd.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba632ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "famd.scree_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute explained inertia manually\n",
    "U, s, V = np.linalg.svd(famd.row_coordinates(X), full_matrices=False)\n",
    "explained_inertia = (s ** 2) / np.sum(s ** 2)\n",
    "\n",
    "# Print explained inertia for each component\n",
    "for i, inertia in enumerate(explained_inertia, start=1):\n",
    "    print(f\"Component {i}: {inertia:.4f} (Explained Variance)\")\n",
    "\n",
    "# Cumulative explained inertia\n",
    "cumulative_inertia = np.cumsum(explained_inertia) * 100\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "for i, cum_inertia in enumerate(cumulative_inertia, start=1):\n",
    "    print(f\"Component {i}: {cum_inertia:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot cummulative Variance\n",
    "plt.plot(range(1, len(cumulative_inertia) + 1), cumulative_inertia, marker='o', \n",
    "         linestyle='--', color='b', label='Cummulative Explained Variance')\n",
    "# Plot individual Variance\n",
    "plt.plot(range(1, len(explained_inertia) + 1), explained_inertia * 100, marker='^', \n",
    "         linestyle='--', color='r', label='Explained Variance')\n",
    "# Annotate cummulative Variance\n",
    "for idx, item in enumerate(cumulative_inertia):\n",
    "    plt.text(idx+1.3, item, f'{item:.2f}', horizontalalignment='right', color='blue')\n",
    "# Annotate Explained Variance\n",
    "for idx, variance in enumerate(explained_inertia):\n",
    "    plt.text(idx+1, variance * 100, f'{(variance*100):.2f}', horizontalalignment='left', verticalalignment='top', color='r')\n",
    "plt.title('Explained Variance & Cumulative Explained Variance by FAMD Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.axhline(y=70, color='black', linestyle='--', label='70% Variance')\n",
    "plt.axhline(y=90, color='black', linestyle='--', label='90% Variance')\n",
    "plt.xticks(range(1, len(cumulative_inertia) + 1))\n",
    "plt.yticks(range(0, 110, 10))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates (loadings) for categorical variable levels\n",
    "categorical_coords = famd.column_coordinates_\n",
    "# categorical_coords.index.name = 'variable'\n",
    "categorical_coords.rename(columns={0:'Component1', 1:'Component2', 2:'Component3', 3:'Component4', 4:'Component5'}, \n",
    "                          inplace=True)\n",
    "\n",
    "# Compute correlations for numerical variables\n",
    "numerical_corrs = []\n",
    "for i in range(X_famd.shape[1]):\n",
    "    component = X_famd.iloc[:, i]\n",
    "    corr = X[columnas_numerical].corrwith(component)\n",
    "    numerical_corrs.append(corr)\n",
    "\n",
    "# Convert to DataFrame with same shape as categorical_coords\n",
    "numerical_corrs_df = pd.concat(numerical_corrs, axis=1)\n",
    "numerical_corrs_df.columns = categorical_coords.columns  # Match FAMD component names\n",
    "numerical_corrs_df.index.name = 'variable'\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "# combined_contributions = categorical_coords.merge(how='left', right=numerical_corrs_df, on='variable')\n",
    "combined_contributions = categorical_coords\n",
    "combined_contributions.update(numerical_corrs_df)\n",
    "\n",
    "# # Optional: sort for better visualization\n",
    "# combined_contributions = combined_contributions.sort_index()\n",
    "\n",
    "# Display result\n",
    "print(combined_contributions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18184ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square the correlations to get contribution approximation\n",
    "contrib = combined_contributions ** 2\n",
    "contrib_norm_df = contrib.div(contrib.sum(axis=0), axis=1) * 100  # Normalize to get % contribution\n",
    "# top_contrib = contrib_norm_df.apply(lambda x: x.sort_values(ascending=False).head(29))\n",
    "for col in contrib_norm_df.columns:\n",
    "    top_contrib = contrib_norm_df.sort_values(ascending=False, by=col)\n",
    "    print(top_contrib[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index so 'variable' becomes a column\n",
    "df_melted = contrib_norm_df.reset_index().melt(id_vars='variable', \n",
    "                                                var_name='Component', \n",
    "                                                value_name='Contribution')\n",
    "df_melted.rename(columns={'variable': 'Variable'}, inplace=True)\n",
    "\n",
    "# Sort variables by average contribution across components (optional, for visual clarity)\n",
    "df_melted['Variable'] = pd.Categorical(\n",
    "    df_melted['Variable'],\n",
    "    categories=(contrib_norm_df.mean(axis=1)\n",
    "                .sort_values(ascending=False)\n",
    "                .index.tolist()),\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Set the color palette for the components\n",
    "palette = sns.color_palette(n_colors=contrib_norm_df.shape[1])\n",
    "\n",
    "# Create the barplot\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(\n",
    "    data=df_melted,\n",
    "    x='Variable',\n",
    "    y='Contribution',\n",
    "    hue='Component',\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "plt.xticks(rotation=90, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylabel('Contribution (%)', fontsize=18)\n",
    "plt.xlabel('Variable', fontsize=18)\n",
    "plt.title('Variable Contributions to FAMD Components', fontsize=20)\n",
    "plt.legend(title='Component', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project individuals and variables\n",
    "row_coords = famd.row_coordinates(X)  # individuals\n",
    "col_coords = famd.column_correlations(X)  # variables\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot individuals (optional: add color by y if you want classes)\n",
    "ax.scatter(row_coords[0], row_coords[1], alpha=0.5, label='Individuals')\n",
    "\n",
    "# Plot variable vectors\n",
    "for i in range(col_coords.shape[0]):\n",
    "    ax.arrow(0, 0, \n",
    "             col_coords.iloc[i, 0], col_coords.iloc[i, 1], \n",
    "             color='red', alpha=0.7, head_width=0.02)\n",
    "    ax.text(col_coords.iloc[i, 0]*1.1, col_coords.iloc[i, 1]*1.1, \n",
    "            col_coords.index[i], color='red', ha='center', va='center')\n",
    "\n",
    "ax.axhline(0, linestyle='--', color='grey')\n",
    "ax.axvline(0, linestyle='--', color='grey')\n",
    "ax.set_xlabel('FAMD Component 1')\n",
    "ax.set_ylabel('FAMD Component 2')\n",
    "ax.set_title('FAMD Biplot: Variables and Individuals')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4048873",
   "metadata": {},
   "source": [
    "### 6.2 PCA with the encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2142714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prince\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select randomly 60% of the dataset\n",
    "X_sample_full = X_encoded.copy()\n",
    "X_sample_full['Assigned'] = y\n",
    "X_sample = X_sample_full.sample(frac=1.0)\n",
    "y_sample = X_sample['Assigned']\n",
    "X_sample.drop(columns=['Assigned'], inplace=True)\n",
    "del X_sample_full\n",
    "\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_pca = pca.fit_transform(X_sample)\n",
    "\n",
    "# Scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, 'o-', color='blue')\n",
    "plt.title('Scree Plot (PCA)')\n",
    "plt.xlabel('Component Number')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Individual factor map\n",
    "individuals = pd.DataFrame(X_pca, columns=[f'F{i+1}' for i in range(pca.n_components)])\n",
    "individuals['DependentBoolean'] = y_sample.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=individuals, x='F1', y='F2', hue='DependentBoolean', palette='viridis')\n",
    "plt.title('Individual Factor Map (F1 vs F2)')\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('F2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "plt.title('Cumulative Explained Variance by PCA Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.7, color='r', linestyle='--', label='70% Variance')\n",
    "plt.axhline(y=0.9, color='g', linestyle='--', label='90% Variance')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

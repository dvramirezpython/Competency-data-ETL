{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Script for creating and analyzing longitudinal data from the Tec21 academic model Cohort 2019 and 2020</h1>\n",
    "\n",
    "#### School: Engineering and Science\n",
    "#### Period: AD2019-FJ2022\n",
    "\n",
    "#### Table of contents                                                                                                                \n",
    "                                            \n",
    "- [1. Datasets creation](#1.-Datasets-creation)                                                                               \n",
    "    - [1.1 Data subset extraction](#4.1-Data-subset-extraction)                                                                     \n",
    "    - [1.2 Statistical description of the selected variables](#4.2-Statistical-description-of-the-selected-variables)               \n",
    "    - [1.3 Graphical description of the selected variables](#4.3-Graphical-description-of-the-selected-variables)                   \n",
    "- [2. Longitudinal analysis](#5.-Longitudinal-analysis)                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import stat\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from ete3 import Tree\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "import seaborn as sbn\n",
    "from ipywidgets import widgets\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.anova as anova\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import scikit_posthocs as sp\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings('ignore')\n",
    "path_files = r'EICData'\n",
    "# path_files= r'/content/drive/MyDrive/Proyecto-Tec21Competences-DataAnalysis/sourcecode/assets/EIC'\n",
    "# path_files = r'EIC-20230322T203344Z-001/EIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "full_df = pd.read_csv(f'EICData\\Transformed_full_df_with_studentid_v1.0.csv', index_col='Unnamed: 0')\n",
    "print(f'Dataframe loaded! \\n The tidy dataframe has {len(full_df.index)} rows and {len(full_df.columns)} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_column', None)\n",
    "#full_df[full_df['student.id']==138480]\n",
    "# full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary code for checking dataset\n",
    "\n",
    "len(full_df[(full_df['program.major_id'] == 'IBQ')\n",
    "        & (full_df['competence.type'] == 'Disciplinary')]['student.id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Cohort\n",
    "atts = full_df['student.cohort.id'].unique().tolist()\n",
    "btn_atts = widgets.Button(description='Select')\n",
    "mult_choice = widgets.SelectMultiple(\n",
    "    options=atts,\n",
    "    description='Select cohort',\n",
    "    disabled=False\n",
    ")\n",
    "display(mult_choice)\n",
    "display(btn_atts)\n",
    "def btn_select_att(btn_atts):\n",
    "    global cohort\n",
    "    cohort = list(mult_choice.value)\n",
    "btn_atts.on_click(btn_select_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the programs\n",
    "programs = full_df['program.major_id'].unique().tolist()\n",
    "atts = full_df['program.major_id'].unique().tolist()\n",
    "btn_atts = widgets.Button(description='Select')\n",
    "mult_choice = widgets.SelectMultiple(\n",
    "    options=atts,\n",
    "    description='Select programs',\n",
    "    disabled=False\n",
    ")\n",
    "display(mult_choice)\n",
    "display(btn_atts)\n",
    "def btn_select_att(btn_atts):\n",
    "    global programs\n",
    "    programs = list(mult_choice.value)\n",
    "btn_atts.on_click(btn_select_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the region\n",
    "regions = full_df['campus.region_name'].unique().tolist()\n",
    "atts = full_df['campus.region_name'].unique().tolist()\n",
    "btn_atts = widgets.Button(description='Select')\n",
    "mult_choice = widgets.SelectMultiple(\n",
    "    options=atts,\n",
    "    description='Select regions',\n",
    "    disabled=False\n",
    ")\n",
    "display(mult_choice)\n",
    "display(btn_atts)\n",
    "def btn_select_att(btn_atts):\n",
    "    global regions\n",
    "    regions = list(mult_choice.value)\n",
    "btn_atts.on_click(btn_select_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sex\n",
    "sex = full_df['student.isWoman'].unique().tolist()\n",
    "atts = full_df['student.isWoman'].unique().tolist()\n",
    "btn_atts = widgets.Button(description='Select')\n",
    "mult_choice = widgets.SelectMultiple(\n",
    "    options=atts,\n",
    "    description='Select sex',\n",
    "    disabled=False\n",
    ")\n",
    "display(mult_choice)\n",
    "display(btn_atts)\n",
    "def btn_select_att(btn_atts):\n",
    "    global sex\n",
    "    sex = list(mult_choice.value)\n",
    "btn_atts.on_click(btn_select_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select grouping var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the region\n",
    "atts = ['campus.region_name', 'student.cohort.id','program.major_id', 'student.isWoman']\n",
    "btn_atts = widgets.Button(description='Select')\n",
    "cb_list = widgets.Dropdown(\n",
    "    options=atts,\n",
    "    description='Select grouping var',\n",
    "    disabled=False,\n",
    ")\n",
    "display(cb_list)\n",
    "display(btn_atts)\n",
    "def btn_select_att(btn_atts):\n",
    "    global grouping_var\n",
    "    grouping_var = cb_list.value\n",
    "btn_atts.on_click(btn_select_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df = full_df[(full_df['student.cohort.id'].isin(cohort))\n",
    "                    & (full_df['program.major_id'].isin(programs))\n",
    "                    & (full_df['campus.region_name'].isin(regions))\n",
    "                    & (full_df['student.isWoman'].isin(sex))]\n",
    "assert (set(cohort_df['student.cohort.id'].unique()) == set(cohort)) \\\n",
    "        & (set(cohort_df['program.major_id'].unique()) == set(programs)) \\\n",
    "        & (set(cohort_df['campus.region_name'].unique()) == set(regions)) \\\n",
    "        & (set(cohort_df['student.isWoman'].unique()) == set(sex)) \\\n",
    "                , f'Error! Cohort column includes {existing_cohort} and selected cohort is {cohort}'\n",
    "print(f'Selected dataframe has {len(cohort_df.index)} rows for:\\n cohort(s) {cohort},\\n program(s) {programs},\\n region(s) {regions},\\n and sex {sex}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by student_id and aggregate semesters into a set\n",
    "grouped = cohort_df.groupby('student.id')['semesters_from.enrollment'].apply(set).reset_index()\n",
    "\n",
    "# Filter students who have semesters 1, 2, 3, 4, 5, and 6\n",
    "filtered_students = grouped[grouped['semesters_from.enrollment'].apply(lambda x: {1, 2, 3, 4, 5, 6}.issubset(x))]\n",
    "\n",
    "# Get the list of student IDs who meet the criteria\n",
    "valid_student_ids = filtered_students['student.id']\n",
    "\n",
    "# Filtering rows belonging to the semesters 1, 2, 3, 4, 5, and 6.\n",
    "filtered_cohort = cohort_df[cohort_df['student.id'].isin(valid_student_ids) \n",
    "                            & cohort_df['semesters_from.enrollment'].isin([1, 2, 3, 4, 5, 6])]\n",
    "\n",
    "len(filtered_cohort['student.id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_list = filtered_cohort['semesters_from.enrollment'].unique()\n",
    "assert set(sem_list) == {1, 2, 3, 4, 5, 6}, f'Error! There is at least one incorrect semester'\n",
    "print(f'Semesters list {sem_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing the Observed_competencies_ratio for students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by student ID and calculate the ratio of True evaluations\n",
    "ratio_df = filtered_cohort.groupby(['student.id', 'semesters_from.enrollment'])['subcompetence.level_assigned'].mean().reset_index()\n",
    "ratio_df.columns = ['student.id', 'semesters_from.enrollment', 'Observed_ratio']\n",
    "\n",
    "# Merge the ratio back to the original dataframe\n",
    "filtered_cohort = filtered_cohort.merge(ratio_df, on=['student.id', 'semesters_from.enrollment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_df = ratio_df.groupby(['student.id'])['semesters_from.enrollment'].unique().apply(tuple)\n",
    "assert tuple_df[tuple_df != (1, 2, 3, 4, 5, 6)].empty, 'Error! There are Students with semesters different to [1, 2, and 3]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying academic program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Version 1, all program into entry programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_mapping = {\n",
    "    'IIT' : 'IIT',\n",
    "    'IIS' : 'IIT',\n",
    "    'IMT' : 'IIT',\n",
    "    'IC'  : 'IIT',\n",
    "    'IE'  : 'IIT',\n",
    "    'IID' : 'IIT',\n",
    "    'IM'  : 'IIT',\n",
    "    'IMD' : 'IIT',\n",
    "    'ICI' : 'ICI',\n",
    "    'IDM' : 'ICI',\n",
    "    'INA' : 'ICI',\n",
    "    'IFI' : 'ICI',\n",
    "    'ICT' : 'ICT',\n",
    "    'ITC' : 'ICT',\n",
    "    'IRS' : 'ICT',\n",
    "    'ITD' : 'ICT',\n",
    "    'IBQ' : 'IBQ',\n",
    "    'IDS' : 'IBQ',\n",
    "    'IBT' : 'IBQ', \n",
    "    'IQ'  : 'IBQ',\n",
    "    'IAG' : 'IBQ',\n",
    "    'IAL' : 'IBQ'\n",
    "}\n",
    "filtered_cohort['program.major_id'] = filtered_cohort['program.major_id'].replace(program_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2. Transforming entry program data into specific programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_program_2(group):\n",
    "#     programs = list(group['program.major_id'].unique())\n",
    "#     if len(programs) > 1:\n",
    "#         group['program.major_id'] = programs[1] if programs[0] in ['IIT', 'ICT', 'IBQ', 'ICI'] else programs[0]\n",
    "#     return group\n",
    "\n",
    "def transform_program_2(group):\n",
    "    programs = list(group['program.major_id'].unique())\n",
    "    if len(programs) > 1:\n",
    "        selected_program = programs[1] if programs[0] in ['IIT', 'ICT', 'IBQ', 'ICI'] else programs[0]\n",
    "        group['program.major_id'] = selected_program\n",
    "    return group\n",
    "\n",
    "filtered_cohort = filtered_cohort.groupby('student.id', as_index=False).apply(transform_program_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "#filtered_cohort[filtered_cohort.index == list(full_df['student.id'].unique())[3]]\n",
    "#filtered_cohort['program.major_id'].value_counts()\n",
    "#len(list(filtered_cohort['student.id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cohort = filtered_cohort.drop_duplicates(subset= ['student.id', 'student.nationality', 'student_originSchool.isITESM', \n",
    "                                                           'student.cohort.id', 'semesters_from.enrollment','student.isWoman', \n",
    "                                                           'campus.region_name', 'program.major_id', 'Observed_ratio'], \n",
    "                                                  keep='first')\n",
    "longitudinal_df = filtered_cohort[['student.id', 'student.nationality', 'student_originSchool.isITESM', \n",
    "                                   'student.cohort.id', 'semesters_from.enrollment','student.isWoman', \n",
    "                                   'campus.region_name', 'program.major_id', 'Observed_ratio']]\n",
    "longitudinal_df.set_index(keys=['student.id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(longitudinal_df.index) == len(filtered_cohort['student.id'].unique()) * 6, 'Error! Rows number mismatch student IDs *times 3'\n",
    "longitudinal_df.sort_values(by='student.id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longitudinal_df[longitudinal_df.index==395]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Until here, we have the data filtered by students, but there are multiple rows for each student. Yet, we need to transform it to add Observed competencies ratio as columns for each student, instead of as nwe rows**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "pivot_df = longitudinal_df.pivot(columns='semesters_from.enrollment', values='Observed_ratio')\n",
    "\n",
    "# Rename the columns to include the semester information\n",
    "pivot_df.columns = [f'Observed_ratio{col}' for col in pivot_df.columns]\n",
    "\n",
    "# Reset the index to make 'student.id' a column again\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# Add other columns\n",
    "pivot_df = pivot_df.merge(longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 1], on='student.id').drop(['Observed_ratio',\n",
    "                                                                                                                     'semesters_from.enrollment'], axis=1)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe numeric variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe categorical and boolean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = pivot_df.select_dtypes(include=['object', 'bool', 'category'])\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Number of unique categories: {pivot_df[col].nunique()}\")\n",
    "    print(f\"Mode: {pivot_df[col].mode()[0]}\")\n",
    "    print(f\"Value counts:\\n{pivot_df[col].value_counts()}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "for col in categorical_cols:\n",
    "    fig = px.bar(\n",
    "        pivot_df[col].value_counts().reset_index(),\n",
    "        x=col, \n",
    "        y='count',\n",
    "        title=f'Distribution of {col}',\n",
    "        labels={'index': col, col: 'Count'},\n",
    "        text_auto=True\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_title=col,\n",
    "        yaxis_title='Count',\n",
    "        title_x=0.5,  # Center the title\n",
    "        xaxis_tickangle=-45  # Rotate x-axis labels if needed\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for col in categorical_cols:\n",
    "    if i != 0 and i != 4:\n",
    "        # Prepare the data for the pie chart\n",
    "        pie_data = pivot_df[col].value_counts().reset_index()\n",
    "        pie_data.columns = [col, 'count']\n",
    "        \n",
    "        # Create the pie chart\n",
    "        fig = px.pie(\n",
    "            pie_data, \n",
    "            names=col,   # Categorical column for slices\n",
    "            values='count',  # Numerical values\n",
    "            #title=f'Distribution of {col}',  # Title of the plot\n",
    "            labels={col: 'Category', 'count': 'Count'},  # Customize labels\n",
    "            hole=0,  # Optional: Adds a hole for a donut-style chart\n",
    "        )\n",
    "        \n",
    "        fig.update_traces(\n",
    "            textposition='inside',  # Place labels inside the slices\n",
    "            textinfo='label+value+percent',  # Show both percentage and category inside the pie\n",
    "            showlegend=False,  # Hide external legend\n",
    "            textfont_size=38\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_x=0.5,  # Center the title\n",
    "            title_font_size=38,  # Adjust title font size\n",
    "            height=600,  # Adjust the overall height of the chart\n",
    "            width=600,  # Adjust the overall width of the chart\n",
    "        )\n",
    "\n",
    "        # Show the figure\n",
    "        fig.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.to_csv(f'EICData\\LongitudinalData_Cohort_{cohort}_LongPrograms_6semesters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longitudinal_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudinal_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longitudinal_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in longitudinal_df.columns:\n",
    "  longitudinal_df.boxplot(by=col, column='Observed_ratio')\n",
    "  plt.suptitle('')\n",
    "  plt.title(f'Boxplots of Observed_ratio by {col}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Longitudinal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q Plot and Histogram\n",
    "def plot_samples(df):\n",
    "    for semester in df['semesters_from.enrollment'].unique():\n",
    "        data = df[df['semesters_from.enrollment'] == int(semester)]['Observed_ratio']\n",
    "        \n",
    "        # Q-Q plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sm.qqplot(data, line='45', fit=True)\n",
    "        plt.title(f'Q-Q Plot for Semester {semester}')\n",
    "        # Set axis limits\n",
    "        plt.xlim([-4, 4])   \n",
    "        plt.ylim([-12, 2])\n",
    "        plt.show()\n",
    "\n",
    "        # Histogram\n",
    "        sbn.histplot(data, kde=True)\n",
    "        plt.title(f'Histogram for Semester {semester}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_smirnov_test(longitudinal_df):\n",
    "    for semester in longitudinal_df['semesters_from.enrollment'].unique():\n",
    "        stat, p = stats.kstest(longitudinal_df[longitudinal_df['semesters_from.enrollment'] == semester]['Observed_ratio'], \n",
    "                        'norm', args=(longitudinal_df['Observed_ratio'].mean(), longitudinal_df['Observed_ratio'].std()))\n",
    "        print(f\"\\nKolmogorov-Smirnov test for semester {semester}:\")\n",
    "        print(f\"Statistics={stat}, p-value={p}\")\n",
    "        if p > 0.05:\n",
    "            print(\"Sample looks Gaussian (fail to reject H0)\")\n",
    "        else:\n",
    "            print(\"Sample does not look Gaussian (reject H0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderson-Darling test for normality\n",
    "def anderson_darleing_test(df):\n",
    "    for semester in df['semesters_from.enrollment'].unique():\n",
    "        result = stats.anderson(df[df['semesters_from.enrollment'] == semester]['Observed_ratio'], dist='norm')\n",
    "        print(f\"\\nAnderson-Darling test for semester {semester}:\")\n",
    "        print(f\"Statistic: {result.statistic}\")\n",
    "        for i in range(len(result.critical_values)):\n",
    "            sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "            if result.statistic < cv:\n",
    "                print(f\"At {sl}% significance level, sample looks Gaussian (fail to reject H0)\")\n",
    "            else:\n",
    "                print(f\"At {sl}% significance level, sample does not look Gaussian (reject H0)\")\n",
    "    return sl, cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudinal_df = longitudinal_df.reset_index()\n",
    "normal_dist = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def friedman_test(df):\n",
    "    # Pivot the DataFrame to wide format\n",
    "    pivot_df = df.pivot(index='student.id', columns='semesters_from.enrollment', values='Observed_ratio')\n",
    "\n",
    "    # Extract data for the Friedman test\n",
    "    data_sem1 = pivot_df[1].values\n",
    "    data_sem2 = pivot_df[2].values\n",
    "    data_sem3 = pivot_df[3].values\n",
    "    data_sem4 = pivot_df[4].values\n",
    "    data_sem5 = pivot_df[5].values\n",
    "    data_sem6 = pivot_df[6].values\n",
    "\n",
    "    # Perform the Friedman test\n",
    "    stat, p = stats.friedmanchisquare(data_sem1, data_sem2, data_sem3, data_sem4, data_sem5, data_sem6)\n",
    "\n",
    "    print(f\"Friedman test statistic: {stat}\")\n",
    "    print(f\"p-value: {p}\")\n",
    "\n",
    "    # Interpretation of results\n",
    "    if p < 0.05:\n",
    "        print(\"There is a significant difference in scores across semesters (reject H0)\")\n",
    "    else:\n",
    "        print(\"There is no significant difference in scores across semesters (fail to reject H0)\")\n",
    "    return stat, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For small samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data requirements for small samples\n",
    "\n",
    "# 1. Check for missing values\n",
    "print(\"Missing values:\\n\", longitudinal_df.isnull().sum())\n",
    "\n",
    "# 2. Descriptive statistics\n",
    "print(\"\\nDescriptive statistics:\\n\", longitudinal_df.describe())\n",
    "\n",
    "# 3. Check for normality using Shapiro-Wilk test\n",
    "for semester in longitudinal_df['semesters_from.enrollment'].unique():\n",
    "    stat, p = stats.shapiro(longitudinal_df[longitudinal_df['semesters_from.enrollment'] == semester]['Observed_ratio'])\n",
    "    print(f\"\\nShapiro-Wilk test for semester {semester}:\")\n",
    "    print(f\"Statistics={stat}, p-value={p}\")\n",
    "    if p > 0.05:\n",
    "        print(\"Sample looks Gaussian (fail to reject H0)\")\n",
    "    else:\n",
    "        print(\"Sample does not look Gaussian (reject H0)\")\n",
    "\n",
    "\n",
    "# Visual inspection\n",
    "plot_samples(longitudinal_df)\n",
    "\n",
    "# 5. Check for homogeneity of variances using Levene's test\n",
    "stat, p = stats.levene(\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 1]['Observed_ratio'],\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 2]['Observed_ratio'],\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 3]['Observed_ratio'],\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 4]['Observed_ratio']\n",
    ")\n",
    "print(f\"\\nLevene's test for homogeneity of variances:\\nStatistics={stat}, p-value={p}\")\n",
    "if p > 0.05:\n",
    "    print(\"Variances are equal (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Variances are not equal (reject H0)\")\n",
    "\n",
    "# Data fit normal distributions, so ANOVA is feasible\n",
    "# Create a wide format dataframe for repeated measures ANOVA\n",
    "df_wide = longitudinal_df.pivot(index='student.id', columns='semesters_from.enrollment', values='Observed_ratio')\n",
    "df_wide.columns = ['Observed_ratio_sem1', 'Observed_ratio_sem2', 'Observed_ratio_sem3']\n",
    "\n",
    "# Reshape data for ANOVA\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars=['student.id'], value_vars=['Observed_ratio_sem1', 'Observed_ratio_sem2', 'Observed_ratio_sem3'])\n",
    "df_long.columns = ['student.id', 'semesters_from.enrollment', 'Observed_ratio']\n",
    "df_long['semesters_from.enrollment'] = df_long['semesters_from.enrollment'].apply(lambda x: int(x[-1]))\n",
    "\n",
    "# ANOVA model\n",
    "model = ols('score ~ C(semesters_from.enrollment) + C(student.id)', data=df_long).fit()\n",
    "anova_results = anova.AnovaRM(df_long, 'Observed_ratio', 'student.id', within=['semesters_from.enrollment']).fit()\n",
    "\n",
    "print(\"\\nANOVA results:\\n\", anova_results)\n",
    "\n",
    "# Interpretation of results\n",
    "p_value = anova_results.anova_table['Pr > F'][0]\n",
    "print(f\"\\nInterpretation of ANOVA results:\\nF-statistic: {anova_results.anova_table['F Value'][0]}, p-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in scores across semesters (reject H0)\")\n",
    "else:\n",
    "    print(\"There is no significant difference in scores across semesters (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For large samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data requirements\n",
    "# 1. Check for missing values\n",
    "print(\"Missing values:\\n\", longitudinal_df.isnull().sum())\n",
    "\n",
    "# 2. Descriptive statistics\n",
    "print(\"\\nDescriptive statistics:\\n\", longitudinal_df.describe())\n",
    "\n",
    "# 3. Tests for normality\n",
    "kolmogorov_smirnov_test(longitudinal_df)\n",
    "anderson_darleing_test(longitudinal_df)\n",
    "\n",
    "# Visual inspection\n",
    "plot_samples(longitudinal_df)\n",
    "\n",
    "# 5. Check for homogeneity of variances using Levene's test\n",
    "stat, p = stats.levene(\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 1]['Observed_ratio'],\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 2]['Observed_ratio'],\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 3]['Observed_ratio'],\n",
    "    longitudinal_df[longitudinal_df['semesters_from.enrollment'] == 4]['Observed_ratio']\n",
    ")\n",
    "print(f\"\\nLevene's test for homogeneity of variances:\\nStatistics={stat}, p-value={p}\")\n",
    "if p > 0.05:\n",
    "    print(\"Variances are equal (fail to reject H0)\")\n",
    "    normal_dist = False\n",
    "else:\n",
    "    print(\"Variances are not equal (reject H0)\")\n",
    "    normal_dist = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If data fits normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data fits normal distributions, ANOVA is feasible\n",
    "# Create a wide format dataframe for repeated measures ANOVA\n",
    "df_wide = longitudinal_df.pivot(index='student.id', columns='semesters_from.enrollment', values='Observed_ratio')\n",
    "df_wide.columns = ['Observed_ratio_sem1', 'Observed_ratio_sem2', 'Observed_ratio_sem3']\n",
    "\n",
    "# Reshape data for ANOVA\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars=['student.id'], value_vars=['Observed_ratio_sem1', 'Observed_ratio_sem2', 'Observed_ratio_sem3'])\n",
    "df_long.columns = ['student.id', 'semesters_from.enrollment', 'Observed_ratio']\n",
    "df_long['semesters_from.enrollment'] = df_long['semesters_from.enrollment'].apply(lambda x: int(x[-1]))\n",
    "\n",
    "# ANOVA model\n",
    "model = ols('score ~ C(semesters_from.enrollment) + C(student.id)', data=df_long).fit()\n",
    "anova_results = anova.AnovaRM(df_long, 'Observed_ratio', 'student.id', within=['semesters_from.enrollment']).fit()\n",
    "\n",
    "print(\"\\nANOVA results:\\n\", anova_results)\n",
    "\n",
    "# Interpretation of results\n",
    "p_value = anova_results.anova_table['Pr > F'][0]\n",
    "print(f\"\\nInterpretation of ANOVA results:\\nF-statistic: {anova_results.anova_table['F Value'][0]}, p-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in scores across semesters (reject H0)\")\n",
    "else:\n",
    "    print(\"There is no significant difference in scores across semesters (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If data does not fit normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Longitudinal analysis with Friedman test\n",
    "# friedman_test(longitudinal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conover_posthoc(data):\n",
    "    \n",
    "    # Friedman test\n",
    "    f_statistic, p_value = friedman_test(data)\n",
    "\n",
    "    print(\"Friedman test:\")\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "\n",
    "    # Conover post-hoc test\n",
    "    if p_value < 0.05:\n",
    "        conover_results = sp.posthoc_conover(data, \n",
    "                                             p_adjust='holm', \n",
    "                                             val_col='Observed_ratio', \n",
    "                                             group_col='semesters_from.enrollment')\n",
    "        print(\"Conover post-hoc test:\")\n",
    "        print(conover_results)\n",
    "    else:\n",
    "        print(\"No significant difference found in the Friedman test.\")\n",
    "    return conover_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add significance annotation\n",
    "def add_stat_annotation(ax, x1, x2, y, h, p, p_corr, reject):\n",
    "    text = \"\"\n",
    "    if p_corr < 0.001:\n",
    "        text = \"***\"\n",
    "    elif p_corr < 0.01:\n",
    "        text = \"**\"\n",
    "    elif p_corr < 0.05:\n",
    "        text = \"*\"\n",
    "    else:\n",
    "        text = \"ns\"\n",
    "    ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c='k')\n",
    "    ax.text((x1 + x2) * .5, y + h, text, ha='center', va='bottom', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcoxon signed-rank test with Bonferroni correction\n",
    "\n",
    "pivot_df = longitudinal_df.pivot(index='student.id', columns='semesters_from.enrollment', values='Observed_ratio')\n",
    "# Number of semesters in the sample\n",
    "semesters = 6\n",
    "\n",
    "# Perform pairwise Wilcoxon signed-rank tests\n",
    "pairwise_test_results = {}\n",
    "for i in range(1, semesters):\n",
    "    for j in range(i + 1, semesters + 1):\n",
    "        var1 = pivot_df[i].dropna().values\n",
    "        var2 = pivot_df[j].dropna().values\n",
    "        stat, p = stats.wilcoxon(var1, var2)\n",
    "        comparison_str = f'Sem{i} vs Sem{j}'\n",
    "        pairwise_test_results[f'{i}{j}'] = (stat, p, comparison_str)\n",
    "\n",
    "# Collect p-values for multiple testing correction\n",
    "p_values = [value[1] for value in pairwise_test_results.values()]\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "reject, p_corrected_bonf, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "# Print the results\n",
    "for index, (key, value) in enumerate(pairwise_test_results.items()):\n",
    "    print(f\"\\nComparison: {value[2]}\")\n",
    "    print(f\"Wilcoxon test statistic: {value[0]}\")\n",
    "    print(f\"p-value: {value[1]}, corrected p-value: {p_corrected[index]}\")\n",
    "    if reject[index]:\n",
    "        print(\"Significant difference (reject H0)\")\n",
    "    else:\n",
    "        print(\"No significant difference (fail to reject H0)\")\n",
    "\n",
    "conover_results = conover_posthoc(longitudinal_df)\n",
    "p_corrected_conover = [conover_results.iloc[i,j] for i in range(conover_results.shape[0]) for j in range(i+1, conover_results.shape[0])]\n",
    "\n",
    "# Plotting\n",
    "medians = longitudinal_df[['semesters_from.enrollment','Observed_ratio']].groupby('semesters_from.enrollment').median()\n",
    "means = longitudinal_df[['semesters_from.enrollment','Observed_ratio']].groupby('semesters_from.enrollment').mean()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot = sbn.boxplot(x='semesters_from.enrollment', y='Observed_ratio', data=longitudinal_df, palette='Set2')\n",
    "for i, mean in enumerate(means['Observed_ratio']):\n",
    "    plot.annotate(str(round(mean, 4)), xy = (i, mean), horizontalalignment = 'center')\n",
    "\n",
    "# Get the max y-value for the placement of significance annotations\n",
    "y_max = longitudinal_df['Observed_ratio'].max()\n",
    "\n",
    "# Add annotations for significant pairwise comparisons\n",
    "pairs = [(i, j) for i in range(semesters) for j in range(i+1, semesters)]\n",
    "step = 7\n",
    "heights = np.array(range(4, (len(pairs) + 1) * step, step))\n",
    "heights = list(heights/100)\n",
    "\n",
    "for i, (x1, x2) in enumerate(pairs):\n",
    "    add_stat_annotation(plot, x1, x2, y_max, heights[i], p_values[i], p_corrected_conover[i], reject[i])\n",
    "\n",
    "plt.title('Boxplot of Scores by Semester with Significance Annotations')\n",
    "plt.xlabel('Semester')\n",
    "plt.ylabel('Observed ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Check why this Conover test outputs a result different to the JASP implementation\n",
    "\n",
    "# Calculate medians and means\n",
    "medians = longitudinal_df.groupby('semesters_from.enrollment')['Observed_ratio'].median().reset_index()\n",
    "means = longitudinal_df.groupby('semesters_from.enrollment')['Observed_ratio'].mean().reset_index()\n",
    "\n",
    "# Create the boxplot using Plotly Express\n",
    "fig = px.box(longitudinal_df, \n",
    "             x='semesters_from.enrollment', \n",
    "             y='Observed_ratio', \n",
    "             #points=\"all\", \n",
    "             color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "\n",
    "# Add mean annotations\n",
    "for i, mean in enumerate(means['Observed_ratio']):\n",
    "    fig.add_annotation(x=means['semesters_from.enrollment'][i], y=mean, \n",
    "                       text=str(round(mean, 4)), \n",
    "                       showarrow=False, \n",
    "                       font=dict(size=12),\n",
    "                       xanchor='center')\n",
    "\n",
    "# Add significance annotations\n",
    "y_max = longitudinal_df['Observed_ratio'].max()\n",
    "\n",
    "pairs = [(i, j) for i in range(semesters) for j in range(i+1, semesters)]\n",
    "step = 0.07  # Adjusted for Plotly's scale\n",
    "heights = [y_max + step * (i + 1) for i in range(len(pairs))]\n",
    "\n",
    "for i, (x1, x2) in enumerate(pairs):\n",
    "    #if reject[i]:\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=medians['semesters_from.enrollment'][x1], y0=heights[i],\n",
    "        x1=medians['semesters_from.enrollment'][x2], y1=heights[i],\n",
    "        line=dict(color=\"black\", width=2)\n",
    "    )\n",
    "    signif = '***' if p_corrected_conover[i] < 0.001 else '**' if p_corrected_conover[i] < 0.01 else '*' if p_corrected_conover[i] < 0.05 else 'ns'\n",
    "    fig.add_annotation(\n",
    "        x=(medians['semesters_from.enrollment'][x1] + medians['semesters_from.enrollment'][x2]) / 2,\n",
    "        y=heights[i],\n",
    "        text= signif,\n",
    "        showarrow=False,\n",
    "        font=dict(size=10),\n",
    "        xanchor=\"center\"\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Boxplot of Scores by Semester with Significance Annotations',\n",
    "    xaxis_title='Semester',\n",
    "    yaxis_title='Observed ratio',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_diagonal(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    below_diag_elements = \n",
    "    \n",
    "    for i in range(1, rows):  # Start from 1 to skip the diagonal\n",
    "        for j in range(i):\n",
    "            below_diag_elements.append(matrix[i, j])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting means in dotplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the dotplot with a connecting line\n",
    "fig = px.line(x=list(longitudinal_df['semesters_from.enrollment'].unique()), \n",
    "              y=medians['Observed_ratio'], \n",
    "              markers=True)\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_layout(title=f'Means of Observed_competencies ratio by semester for cohort(s) {cohort}', xaxis_title='Semester', yaxis_title='Means of Observed_competencies ratio')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "lower_bound = longitudinal_df[['semesters_from.enrollment',\n",
    "                               'Observed_ratio']].groupby('semesters_from.enrollment').apply(lambda x: stats.t.interval(0.95, \n",
    "                                                                                                                        len(x)-1, \n",
    "                                                                                                                        loc=x.mean(), \n",
    "                                                                                                                        scale=stats.sem(x))[0])\n",
    "upper_bound = longitudinal_df[['semesters_from.enrollment',\n",
    "                               'Observed_ratio']].groupby('semesters_from.enrollment').apply(lambda x: stats.t.interval(0.95, \n",
    "                                                                                                                        len(x)-1, \n",
    "                                                                                                                        loc=x.mean(), \n",
    "                                                                                                                        scale=stats.sem(x))[1])\n",
    "\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['means'] = means['Observed_ratio']\n",
    "temp_df['lower_bound'] = [(means.iloc[i-1,0] - lower_bound[i][1]) for i in lower_bound.index]\n",
    "temp_df['upper_bound'] = [(upper_bound[i][1] - means.iloc[i-1,0]) for i in upper_bound.index]\n",
    "# Create the plot\n",
    "fig = px.line(temp_df, \n",
    "              x=longitudinal_df['semesters_from.enrollment'].unique(),\n",
    "              y='means', \n",
    "              error_y='lower_bound', \n",
    "              error_y_minus='upper_bound',\n",
    "              markers=True)\n",
    "fig.update_traces(marker=dict(color='red'))           \n",
    "fig.update_layout(title=f'Means of Observed_competencies ratio by semester for cohort(s) {cohort}',\n",
    "                  xaxis_title='Semester',\n",
    "                  yaxis_title='Means of Observed_competencies ratio')\n",
    "\n",
    "#pio.write_image(fig, 'line_plot.svg')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig, 'line_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcoxon signed-rank test with Bonferroni correction\n",
    "# from scipy.stats import wilcoxon\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# from itertools import combinations\n",
    "\n",
    "# # Pivot the DataFrame to wide format\n",
    "# pivot_df = longitudinal_df.pivot(index='student.id', columns='semesters_from.enrollment', values='Observed_ratio')\n",
    "\n",
    "# # Calculate means\n",
    "# means = longitudinal_df.groupby('semesters_from.enrollment')['Observed_ratio'].mean().reset_index()\n",
    "\n",
    "# # Perform pairwise Wilcoxon signed-rank tests\n",
    "# samples = longitudinal_df['semesters_from.enrollment'].unique()\n",
    "# pairwise_combinations = list(combinations(samples, 2))\n",
    "# p_values = []\n",
    "\n",
    "# for comb in pairwise_combinations:\n",
    "#     sample1 = longitudinal_df[longitudinal_df['semesters_from.enrollment'] == comb[0]]['Observed_ratio']\n",
    "#     sample2 = longitudinal_df[longitudinal_df['semesters_from.enrollment'] == comb[1]]['Observed_ratio']\n",
    "#     stat, p = wilcoxon(sample1, sample2)\n",
    "#     p_values.append(p)\n",
    "\n",
    "# # Apply Bonferroni correction\n",
    "# bonferroni_correction = len(p_values)\n",
    "# corrected_p_values = np.array(p_values) * bonferroni_correction\n",
    "# corrected_p_values[corrected_p_values > 1] = 1  # Cap the maximum p-value at 1\n",
    "\n",
    "# # Determine which pairs have significant differences\n",
    "# significant_pairs = [pairwise_combinations[i] for i, p in enumerate(corrected_p_values) if p < 0.05]\n",
    "\n",
    "# # Create plot\n",
    "# fig = go.Figure()\n",
    "\n",
    "# # Add means\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=means['semesters_from.enrollment'],\n",
    "#     y=means['Observed_ratio'],\n",
    "#     mode='markers+text',\n",
    "#     text=means['Observed_ratio'],\n",
    "#     textposition='top center',\n",
    "#     name='Means'\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Intersubject longitudinal study**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.libqsturng import qsturng\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "# Friedman Test\n",
    "for group in list(longitudinal_df[grouping_var].unique().tolist()):\n",
    "    group_data = longitudinal_df[longitudinal_df[grouping_var] == group]\n",
    "    values = [group_data[group_data['semesters_from.enrollment'] == t]['Observed_ratio'] for t in range(1, 5)]\n",
    "    stat, p = friedmanchisquare(*values)\n",
    "    print(f'Friedman Test for group {group}: statistic={stat}, p-value={p}')\n",
    "\n",
    "# Wilcoxon Signed-Rank Test\n",
    "for t1, t2 in [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]:\n",
    "    stat, p = wilcoxon(longitudinal_df[longitudinal_df['semesters_from.enrollment'] == t1]['Observed_ratio'],\n",
    "                       longitudinal_df[longitudinal_df['semesters_from.enrollment'] == t2]['Observed_ratio'])\n",
    "    print(f'Wilcoxon Signed-Rank Test between time {t1} and {t2}: statistic={stat}, p-value={p}')\n",
    "\n",
    "# Kruskal-Wallis Test\n",
    "for t in range(1, 5):\n",
    "    stat, p = kruskal(longitudinal_df[longitudinal_df['semesters_from.enrollment'] == t][longitudinal_df['student.cohort.id'] == 2019.0]['Observed_ratio'],\n",
    "                      longitudinal_df[longitudinal_df['semesters_from.enrollment'] == t][longitudinal_df['student.cohort.id'] == 2020.0]['Observed_ratio'])\n",
    "    print(f'Kruskal-Wallis Test at time {t}: statistic={stat}, p-value={p}')\n",
    "\n",
    "# Quade Test - Using statsmodels for factorial analysis\n",
    "longitudinal_df['value_ranked'] = longitudinal_df.groupby('semesters_from.enrollment')['Observed_ratio'].rank()\n",
    "model = ols(\"value_ranked ~ C('student.cohort.id') + C('semesters_from.enrollment') + C('student.cohort.id'):C('semesters_from.enrollment')\", \n",
    "            data=longitudinal_df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(f'Quade Test:\\n{anova_table}')\n",
    "\n",
    "# Aligned Rank Transform (ART)\n",
    "# We'll use the ART module from the ARTool package which is not available in Python by default.\n",
    "# This step is a placeholder as the ARTool package needs to be used in R or other software.\n",
    "# from art import ART\n",
    "# art = ART()\n",
    "# art.fit(df['value'], df['group'], df['time'])\n",
    "# art_anova = art.anova_table()\n",
    "# print(f'Aligned Rank Transform (ART):\\n{art_anova}')\n",
    "\n",
    "# Note: ART can be done using the ARTool package in R and then imported into Python if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupytercudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
